{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df50bc99",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Engineering with scikit-learn Pipelines\n",
    "\n",
    "This notebook follows the instructor guidance and walks through:\n",
    "\n",
    "- A manual approach to preprocessing (to show the detailed steps and pitfalls),\n",
    "- A clean, reproducible approach using scikit-learn `Pipeline` and `ColumnTransformer`.\n",
    "\n",
    "Dataset: the UCI \"Adult\" (Census Income) dataset. Task: predict whether income >50K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6d7a5",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this activity you will be able to:\n",
    "\n",
    "1. Load and inspect a tabular dataset with pandas.\n",
    "2. Identify numeric vs categorical features and handle missing values.\n",
    "3. Perform manual preprocessing: imputation, encoding, scaling, and combining features.\n",
    "4. Build a single, end-to-end `Pipeline` that encapsulates preprocessing and modeling.\n",
    "5. Appreciate why pipelines prevent data leakage and make models easier to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7de467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2595e6a",
   "metadata": {},
   "source": [
    "## Load the Adult Census dataset\n",
    "\n",
    "We fetch the data directly from the UCI repository. The dataset has no header, so we assign column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533b0ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (48842, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass      education  education-num       marital-status  \\\n",
       "0   25     Private           11th              7        Never-married   \n",
       "1   38     Private        HS-grad              9   Married-civ-spouse   \n",
       "2   28   Local-gov     Assoc-acdm             12   Married-civ-spouse   \n",
       "3   44     Private   Some-college             10   Married-civ-spouse   \n",
       "4   18           ?   Some-college             10        Never-married   \n",
       "\n",
       "           occupation relationship    race      sex  capital-gain  \\\n",
       "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
       "1     Farming-fishing      Husband   White     Male             0   \n",
       "2     Protective-serv      Husband   White     Male             0   \n",
       "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
       "4                   ?    Own-child   White   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country   class  \n",
       "0             0              40   United-States   <=50K  \n",
       "1             0              50   United-States   <=50K  \n",
       "2             0              40   United-States    >50K  \n",
       "3             0              40   United-States    >50K  \n",
       "4             0              30   United-States   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/adult-census.csv')\n",
    "\n",
    "print('Dataset loaded. Shape:', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e652d1",
   "metadata": {},
   "source": [
    "## Part 1 â€” Manual Approach (Without Pipelines)\n",
    "\n",
    "We will perform each preprocessing step explicitly to show what a pipeline automates later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       48842 non-null  object\n",
      " 2   education       48842 non-null  object\n",
      " 3   education-num   48842 non-null  int64 \n",
      " 4   marital-status  48842 non-null  object\n",
      " 5   occupation      48842 non-null  object\n",
      " 6   relationship    48842 non-null  object\n",
      " 7   race            48842 non-null  object\n",
      " 8   sex             48842 non-null  object\n",
      " 9   capital-gain    48842 non-null  int64 \n",
      " 10  capital-loss    48842 non-null  int64 \n",
      " 11  hours-per-week  48842 non-null  int64 \n",
      " 12  native-country  48842 non-null  object\n",
      " 13  class           48842 non-null  object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Quick EDA - Exploratory Data Analysis\n",
    "# This shows us data types, non-null counts, and memory usage\n",
    "# Look for: mixed types, missing values (shown as non-null count < total rows)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6938b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  education-num  capital-gain  capital-loss  hours-per-week\n",
       "count  48842.000000   48842.000000  48842.000000  48842.000000    48842.000000\n",
       "mean      38.643585      10.078089   1079.067626     87.502314       40.422382\n",
       "std       13.710510       2.570973   7452.019058    403.004552       12.391444\n",
       "min       17.000000       1.000000      0.000000      0.000000        1.000000\n",
       "25%       28.000000       9.000000      0.000000      0.000000       40.000000\n",
       "50%       37.000000      10.000000      0.000000      0.000000       40.000000\n",
       "75%       48.000000      12.000000      0.000000      0.000000       45.000000\n",
       "max       90.000000      16.000000  99999.000000   4356.000000       99.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics for numeric columns\n",
    "# This shows mean, std, min, max, and quartiles\n",
    "# Look for: outliers, scale differences, and distribution patterns\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed55a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "age               0\n",
      "workclass         0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "class             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values using pandas isnull()\n",
    "# Note: This dataset uses ' ?' as a missing value indicator\n",
    "# pandas won't recognize ' ?' as missing - we need to handle this explicitly\n",
    "print(\"Missing values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28a52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "class\n",
      "<=50K    37155\n",
      ">50K     11687\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check target distribution\n",
    "# Important: Check if the dataset is balanced or imbalanced\n",
    "# This affects model training and evaluation metrics\n",
    "print(\"Target distribution:\")\n",
    "print(data['class'].value_counts())\n",
    "\n",
    "# Visualize target distribution for better understanding\n",
    "plt.figure(figsize=(8, 5))\n",
    "data['class'].value_counts().plot(kind='bar')\n",
    "plt.title('Income Distribution')\n",
    "plt.xlabel('Income Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e8e2e",
   "metadata": {},
   "source": [
    "## Define Feature Types\n",
    "\n",
    "We need to identify which features are numerical and which are categorical, as they require different preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "070d9098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features (5): ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\n",
      "Categorical features (7): ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
      "\n",
      "Target: class\n"
     ]
    }
   ],
   "source": [
    "# Define numerical features (continuous or discrete numbers)\n",
    "numerical_features = ['age', 'education-num', 'capital-gain', \n",
    "                      'capital-loss', 'hours-per-week']\n",
    "\n",
    "# Define categorical features (text categories)\n",
    "categorical_features = ['workclass', 'marital-status', \n",
    "                       'occupation', 'relationship', 'race', 'sex', \n",
    "                       'native-country']\n",
    "\n",
    "# Target variable\n",
    "target = 'class'\n",
    "\n",
    "print(f\"Numerical features ({len(numerical_features)}): {numerical_features}\")\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"\\nTarget: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e8e2e",
   "metadata": {},
   "source": [
    "### Preprocessing Steps\n",
    "\n",
    "Our manual preprocessing will follow these steps:\n",
    "\n",
    "1.  **Handle Missing Values**: The dataset uses `' ?'` to denote missing values. We'll replace these with `NaN` and then use imputation to fill them. For categorical columns, we'll use the most frequent value (mode), and for numerical columns, we'll use the mean.\n",
    "2.  **Encode Categorical Features**: We will convert categorical text data into a numerical format using one-hot encoding. This creates a new binary column for each category.\n",
    "3.  **Scale Numerical Features**: To ensure that all features contribute equally to the model, we will scale numerical features to have a mean of 0 and a standard deviation of 1 (Standardization).\n",
    "4.  **Split Data**: We'll split the data into training and testing sets to evaluate our model's performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f53fb",
   "metadata": {},
   "source": [
    "### Step 1: Handle Missing Values\n",
    "\n",
    "First, let's replace the `' ?'` strings with `NaN` so pandas recognizes them as missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219f412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after replacing ' ?':\n",
      "age                  0\n",
      "workclass         2799\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        2809\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     857\n",
      "class                0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 6465\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Replace ' ?' with NaN (Not a Number)\n",
    "# Why? The dataset uses ' ?' (string with space) to indicate missing values\n",
    "# We need to convert these to NaN so pandas and sklearn recognize them as missing\n",
    "\n",
    "data_manual = data.copy()  # Create a copy to preserve original data\n",
    "data_manual = data_manual.replace(' ?', np.nan)  # Replace all ' ?' with NaN\n",
    "\n",
    "# Verify the replacement worked by checking for missing values\n",
    "print(\"Missing values after replacing ' ?':\")\n",
    "print(data_manual.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {data_manual.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03517ce",
   "metadata": {},
   "source": [
    "Now we can see the actual missing values. Let's visualize their distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ff4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWLFJREFUeJzt3Qd4FOX3//0Teu/SpIv0XqSISi+CgmBBUDqIglKkg1QVQelVvtJUEFFRKUrvTQXpTaqgVOm95rnO+T+zv90QIIFMNsm+X9e1JjszO5nd4GQ+c9/3uYOCg4ODBQAAAAAARLhYEb9LAAAAAABA6AYAAAAAwEW0dAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAgRggKCpK+fftG+H6zZcsmTZo0kZigfPny9oiK9Henv8P//vvP34cCAECEInQDAKKMKVOmWPDSx+rVq+9aHxwcLJkzZ7b1tWrVkphq1qxZ9h6/+OKLe26zaNEi22bkyJGRemzRnd50cP6NhXzs3r3blZ85duxY+7cNAAhMcfx9AAAAhJQgQQKZPn26lCtXzmf5ihUr5J9//pH48ePf9ZqrV69KnDgR/2dtz549EitW5N6jrlmzpiRPntw+gxYtWoS6ja6LHTu21K9fP1KPLSbIlCmTDBw48K7lGTNmdC10p0mTJsb0mAAAhA+hGwAQ5Tz//PPy3XffWSuud5DWoFm8ePFQuyBrUHdDaAHfbfozX375ZZk8ebIcPXr0rjB47do1+fHHH6VKlSqSNm3aSD++6E5vaLzxxhsSnWmvD/13kDBhQn8fCgDgAeheDgCIcl5//XU5ffq0daF23LhxQ77//ntp0KBBmMZ0X7x4Udq3b29jsjXEajjVkPrnn396ttm7d6/Uq1dP0qdPb6FdW0C15fj8+fP3HNPtdIFfs2aNdOzYUR577DFJnDixvPTSS3Lq1CmfY7pz544dk4bmRIkSSYUKFWTnzp1hGieuoVBfP2PGjLvWzZs3z46xYcOG9lzDecWKFe096nvNly+fjBs37gGf8v+9l0OHDvksX758uS3Xr95+++03qV69uoVWfT/PPfecfQ7ewvK534/eUHn11VclWbJkkjp1amnXrp2FS4f+zMKFC4f62ty5c0u1atXkUV2/fl369OkjOXPmtPegQxq6dOliy72F5XPXz2HHjh3WS8Ppxu6Mq3fGsYfl96L70SEVCxYskBIlSljY/vzzz23duXPn7DPX49Tj0OMeNGiQ/fsBAPgfLd0AgChHA0aZMmXkm2++kRo1atiyX3/91YKmhuKwjGNu3bq1hfS2bdtaGNIQr+PEd+3aJcWKFbMQrwFNg9S7775rwfvff/+VuXPnWojRYHk/+pqUKVNaONNwNHz4cPtZ3377rWeb7t27y+DBg+WFF16wn7Vlyxb76h0i7+XZZ5+1mwDauq/h3psu09Bbp04de65BL3/+/PLiiy9az4A5c+bIO++8Y6GrTZs2EhGWLl1qvwvtaaDvWbvcO6Fz1apV8tRTT4Xpc38QDdz6+9fu3+vXr7ff9dmzZ+XLL7+09W+++aa0bNlStm/fLgUKFPC87o8//pC//vpLevXq9cCfcfv27bt6S+hNlyRJkthnpp+jHnOrVq0kb968sm3bNhk2bJjt/6effvK8Jiyfu/670H8ruu+ePXvasnTp0snDDnXQG1JvvfWWfQZ6k+HKlSt2I0L/7eryLFmyyNq1a+3f3rFjx+znAwD8LBgAgChi8uTJwfqn6Y8//ggePXp0cNKkSYOvXLli61555ZXgChUq2PdZs2YNrlmzps9r9XV9+vTxPE+ePHlwmzZt7vmzNm3aZK/57rvv7ntM+rMaN2581zFWrlw5+M6dO57lHTp0CI4dO3bwuXPn7Pnx48eD48SJE1ynTh2f/fXt29de773Pe+ncubNtu2fPHs+y8+fPBydIkCD49ddf9yxzPiNv1apVC86RI4fPsueee84eId/LwYMHfbZbtmyZLdevSt/nk08+afv0fs/6c7Nnzx5cpUqVMH/u96K/O/2ZL774os/yd955x5Zv2bLFnuvnq++/a9euPtu99957wYkTJw6+dOnSfX+Ovn/dX8iH8/v46quvgmPFihW8atUqn9eNHz/etluzZo3P+w/L554/f36fzz3kew4ptN+L/jvUZfPnz/fZdsCAAfa+//rrL5/l3bp1s3+Phw8fvu/nAQBwH93LAQBRkrZ4anE0bXnWLsv69V5dy0OTIkUK6w6tY6JD47Rka3ddbS0ML20F9e4a/Mwzz1gL6t9//23PlyxZIrdu3bKWT2/a6hlWzrhjbdl2/PDDD9ZS7nQtV97jerU3gLbiauvngQMHfLrKP6zNmzdbV3z9/LXlWvevj8uXL0ulSpVk5cqVnq7MD/rcHyRky7zzef3yyy+e31vt2rWtF8T/u9fy/1qutYeBtvxrV/8H0ZZ0Hbrg/dDu40prCWjrdp48eTzvUx/aoq+WLVsWaZ97SNmzZ7+r+7wer/7b014X3sdbuXJl+1z0dwMA8C+6lwMAoiQdK63BQQOnhmINEFpcLKy0W3fjxo1tnKt2idbibI0aNZIcOXJ4Aox22x46dKhMmzbNgot2E9ag+6Cu5Uq78XrT0KO0K7RywreOr/WWKlUqz7YPUqhQIetCrQHTGa+un4dWwvYOXzquWrt8r1u37q4bCBr+wvJ+7kcDt9LP81705+j7etDn/iBPPvmkz/MnnnjCurJ7j2/W/WnI1m7t2g1/8eLFcuLECet6HhYazPXf1r3eq3aF139/oTl58mSkfe4h6b/Z0I5369atYTpeAIB/ELoBAFGWtqzq2NXjx4/beGJtRQ1PS7kGaa3yvXDhQvn000+tuJTOge2MEx8yZIgVNPv5559tm/fee88zlljHU9+PTtcVGqf1NaLoTYBu3brJhg0b7Ji0pVXH7jpV3ffv32+tzdoyqzcQNOzGixfPWoZ1HPL9immFVsRL6Q0Ob84+9DMsUqRIqK/RMcth/dzDI7Rj1BsOOi7666+/ttCtX3VM/r2CdHjoey1YsKB9lqHRz/dRP/f7vbfQPn9HaJXK9edooTqnpT6kXLlyPfA4AADuInQDAKIsrQiuAVNDsHeBsrDKkCGDde/Wh7b4aSGvjz76yCf8acDShxbg0gJUTz/9tIwfP14+/PDDRzr2rFmz2td9+/b5tFBq92ynNTwstHCWFsXSFm7dpwYy767lWrxLi8HNnj3bp/Xduxv0vTgt7lo4zpvTSu/d2qy0onhYgm1YPvd70ZZb789LPz8Nltol3PuGh96Q0SrfGui1uJnenLnXjZDw0PeqBe80UN8rFIf3c7/Xfrw/f+8bSiE//wcd76VLlyLkhgMAwB2M6QYARFnaeqoVorVrtVYADysNpiHH1Oq0Tjp1lzPt04ULF2zMtTcN39qVOeTUUA9DQ5u2RoecQmr06NHh2o8GOm051psO2qKrgbRs2bKe9U7Q9G5h1/eulcUfxAnT3uN+9bObMGGCz3baTVy3/eyzzyzgheRMlRaWz/1BxowZ4/N81KhR9jVkYNeu5HrzQm/K6DFF1Lzb2lKvlcD/97//3bVOawzoOPbwfu7anT3kjY17ff66/6lTp4breLV7u9YmCEl/Zsh/4wCAyEdLNwAgSrvfOOJ70cJr2hVbx4DrnM4a3nXcr04rpV3KnSmwdFqrV155xbrgajj56quvLEzp3N2PSrs/6xzT+vN0rLjOb60tqDr1mY7Jvl8rakgaKLVwmxYnc6adclStWtW6NetNCSeAamDUsKtTRt2PTndVunRpa0k/c+aMjTfXecFDBjW9EfHFF19Y8NXXNG3aVB5//HELp9qyqy3g2vIbls/9QQ4ePOj5vDRM6o0GbdUOOTd30aJFbby7U/gsLNORhYWG+ZkzZ9rUZ/retOeD3kzYvXu3LXfmyQ7P5643LfTmi/ae0DH+uo0WZtN96E2V5s2bS+fOne3f3qRJk2x89uHDh8N0vPo6bW3XObx1qIT+LA3uOs2ZTt2mY+H13xsAwI8ioUI6AADhnjLsfh40Zdj169dtuq3ChQvbtGM6pZJ+P3bsWM/2Bw4cCG7WrFnwE088YVNQpUqVyqYkW7x4cZimDAt5jCGn2VK3bt0K/uCDD4LTp08fnDBhwuCKFSsG79q1Kzh16tTBrVu3DvO/ijNnzgTHjx/f9r9z58671s+ePTu4UKFC9j6yZcsWPGjQoOBJkybdNe1UyCnD1P79+236M91/unTpgnv06BG8aNGiu96LM81a3bp17fh1e/1sXn311eAlS5aE+XO/F2f6LH1/L7/8sr0+ZcqUwW3btg2+evVqqK8ZPHiwvebjjz8O82ep71+n8LqfGzdu2Geo2+n71OMoXrx4cL9+/WzKtvB+7jp9nP571fek67x/Bxs3bgwuVapUcLx48YKzZMkSPHTo0HtOGRby37zj4sWLwd27dw/OmTOn7SdNmjTBZcuWDf7ss8/svQAA/CtI/+PP0A8AQCDRLr86lldbPUO2WiN8RowYIR06dLDW3JDV5AEAiCoY0w0AgEt0DHBIw4cPt6/ly5fnc38E2mYwceJEmxebwA0AiMoY0w0AgEu0+JlW2Na5qnV88+rVq23ObR3Lq2OFEX46XlnHMOt4ax23rNO9AQAQlRG6AQBwSaFChayC+eDBg61aulNc7VGnIwtkWildC6vpFFs9evSwomsAAERljOkGAAAAAMAljOkGAAAAAMAlhG4AAAAAAFzCmO4wuHPnjhw9elSSJk0qQUFBbv0uAAAAAADRaCaNixcvSsaMGSVWrHu3ZxO6w0ADd+bMmSPy9wMAAAAAiAGOHDkimTJluud6QncYaAu382EmS5Ys4n47AAAAAIBoSWcm0cZZJy/eC6E7DJwu5Rq4Cd0AAAAAAMeDhiBTSA0AAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJfEcWvHCGzZus3z9yEghjr0SU1/HwIAAAAQZrR0AwAAAADgElq6AQCghw5cRA8dAAhstHQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAAMTF0Dxw4UEqWLClJkyaVtGnTSp06dWTPnj0+25QvX16CgoJ8Hq1bt/bZ5vDhw1KzZk1JlCiR7adz585y69Ytn22WL18uxYoVk/jx40vOnDllypQpkfIeAQAAAACBy6+he8WKFdKmTRtZv369LFq0SG7evClVq1aVy5cv+2zXsmVLOXbsmOcxePBgz7rbt29b4L5x44asXbtWpk6daoG6d+/enm0OHjxo21SoUEE2b94s7du3lxYtWsiCBQsi9f0CAAAAAAJLHH/+8Pnz5/s817CsLdUbN26UZ5991rNcW7DTp08f6j4WLlwoO3fulMWLF0u6dOmkSJEiMmDAAOnatav07dtX4sWLJ+PHj5fs2bPLkCFD7DV58+aV1atXy7Bhw6RatWouv0sAAAAAQKCKUmO6z58/b19TpUrls3zatGmSJk0aKVCggHTv3l2uXLniWbdu3TopWLCgBW6HBukLFy7Ijh07PNtUrlzZZ5+6jS4HAAAAACBGtnR7u3PnjnX7fvrppy1cOxo0aCBZs2aVjBkzytatW60FW8d9z5o1y9YfP37cJ3Ar57muu982GsyvXr0qCRMm9Fl3/fp1ezh0OwAAAAAAom3o1rHd27dvt27f3lq1auX5Xlu0M2TIIJUqVZL9+/fLE0884VqBt379+rmybwAAAABA4IgS3cvbtm0rc+fOlWXLlkmmTJnuu22pUqXs6759++yrjvU+ceKEzzbOc2cc+L22SZYs2V2t3Eq7sGtXd+dx5MiRR3yHAAAAAIBA5NfQHRwcbIH7xx9/lKVLl1qxswfR6uNKW7xVmTJlZNu2bXLy5EnPNloJXQN1vnz5PNssWbLEZz+6jS4PjU4rpq/3fgAAAAAAEK1Ct3Yp//rrr2X69Ok2V7eOvdaHjrNW2oVcK5FrNfNDhw7J7NmzpVGjRlbZvFChQraNTjGm4frNN9+ULVu22DRgvXr1sn1reFY6r/eBAwekS5cusnv3bhk7dqzMnDlTOnTo4M+3DwAAAACI4fwauseNG2fdt8uXL28t187j22+/tfU63ZdOBabBOk+ePPL+++9LvXr1ZM6cOZ59xI4d27qm61dtuX7jjTcsmPfv39+zjbagz5s3z1q3CxcubFOHffHFF0wXBgAAAACIuYXUtHv5/WTOnFlWrFjxwP1odfNffvnlvttosN+0aVO4jxEAAAAAgGhdSA0AAAAAgJiI0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAABAVAndR44ckX/++cfz/Pfff5f27dvLhAkTIvrYAAAAAAAIrNDdoEEDWbZsmX1//PhxqVKligXvnj17Sv/+/d04RgAAAAAAAiN0b9++XZ566in7fubMmVKgQAFZu3atTJs2TaZMmeLGMQIAAAAAEBih++bNmxI/fnz7fvHixfLiiy/a93ny5JFjx45F/BECAAAAABAooTt//vwyfvx4WbVqlSxatEiqV69uy48ePSqpU6d24xgBAAAAAAiM0D1o0CD5/PPPpXz58vL6669L4cKFbfns2bM93c4BAAAAAIBInPB+CBq2//vvP7lw4YKkTJnSs7xVq1aSKFEiPlMAAAAAAB5lnu7g4GDZuHGjtXhfvHjRlsWLF4/QDQAAAADAo7R0//333zaO+/Dhw3L9+nWbMixp0qTW7Vyf63hvAAAAAADwEC3d7dq1kxIlSsjZs2clYcKEnuUvvfSSLFmyhM8UAAAAAICHbenWquU6L7d2J/eWLVs2+ffff8O7OwAAAAAAYqxwt3TfuXNHbt++fdfyf/75x7qZAwAAAACAhwzdVatWleHDh3ueBwUFyaVLl6RPnz7y/PPPh3d3AAAAAADEWOHuXj5kyBCpVq2a5MuXT65duyYNGjSQvXv3Spo0aeSbb75x5ygBAAAAAAiE0J0pUybZsmWLzJgxQ7Zu3Wqt3M2bN5eGDRv6FFYDAAAAACDQxXmoF8WJI2+88UbEHw0AAAAAAIEcur/88sv7rm/UqNGjHA8AAAAAAIEbunWebm83b96UK1eu2BRiiRIlInQDAAAAAPCw1cvPnj3r89Ax3Xv27JFy5cpRSA0AAAAAgEcJ3aF58skn5ZNPPrmrFRwAAAAAgEAWIaHbKa529OjRiNodAAAAAACBN6Z79uzZPs+Dg4Pl2LFjMnr0aHn66acj8tgAAAAAAAis0F2nTh2f50FBQfLYY49JxYoVZciQIRF5bAAAAAAABFbovnPnjjtHAgAAAABADBNhY7ofxsCBA6VkyZKSNGlSSZs2rbWiayV0b9euXZM2bdpI6tSpJUmSJFKvXj05ceKEzzaHDx+WmjVr2pRlup/OnTvLrVu3fLZZvny5FCtWTOLHjy85c+aUKVOmRMp7BAAAAAAErjC1dHfs2DHMOxw6dGiYt12xYoUFag3eGpJ79OghVatWlZ07d0rixIltmw4dOsi8efPku+++k+TJk0vbtm2lbt26smbNGlt/+/ZtC9zp06eXtWvX2vjyRo0aSdy4ceXjjz+2bQ4ePGjbtG7dWqZNmyZLliyRFi1aSIYMGaRatWphPl4AAAAAAMIjKFgroT1AhQoVwrazoCBZunSpPKxTp05ZS7WG8WeffVbOnz9v48WnT58uL7/8sm2ze/duyZs3r6xbt05Kly4tv/76q9SqVcsqp6dLl862GT9+vHTt2tX2Fy9ePPteg/v27ds9P6t+/fpy7tw5mT9//gOP68KFCxb49XiSJUv20O8vkGTrNs/fh4AY6tAnNf19CIihOG/BLZy3ACBmCmtODFNL97JlyyQy6MGqVKlS2deNGzfKzZs3pXLlyp5t8uTJI1myZPGEbv1asGBBT+BW2nr99ttvy44dO6Ro0aK2jfc+nG3at28fKe8LAAAAABCYwl1IzS1aoE1DsE47VqBAAVt2/Phxa6lOkSKFz7YasHWds4134HbWO+vut43embh69aokTJjQZ93169ft4dDtAAAAAACIlNC9YcMGmTlzphUwu3Hjhs+6WbNmPcwubWy3dv9evXq1+JsWeOvXr5+/DwMAAAAAEGjVy2fMmCFly5aVXbt2yY8//mjdv7Ubt47l1v7sD0OLo82dO9e6sWfKlMmzXIujaajXsdfetHq5rnO2CVnN3Hn+oG20333IVm7VvXt36+ruPI4cOfJQ7wsAAAAAENjCHbq1IviwYcNkzpw51vV7xIgRVtzs1VdftbHW4aE13DRwa3jX0J49e3af9cWLF7cq5Fpt3KFTimkLe5kyZey5ft22bZucPHnSs82iRYssUOfLl8+zjfc+nG2cfYSk04rp670fAAAAAAC4Hrr3799v028pDd2XL1+2quU6tdeECRPC3aX866+/turkOle3jr3Wh46zVtpy3rx5c5uyTFvBtbBa06ZNLSxrETWlU4xpuH7zzTdly5YtsmDBAunVq5ftW8Oz0qnCDhw4IF26dLEbBGPHjrXu8XrMAAAAAABEmdCdMmVKuXjxon3/+OOPe6bh0i7gV65cCde+xo0bZ923y5cvb3NmO49vv/3Ws422quuUYPXq1bNpxLSruPe48dixY1vXdP2qYfyNN96webr79+/v2UZb0HXKMG3dLly4sAwZMkS++OIL5ugGAAAAAEStQmoafDW86jRdr7zyirRr1866huuySpUqhWtfYZgiXBIkSCBjxoyxx71kzZpVfvnll/vuR4P9pk2bwnV8AAAAAABESujWFm2dymv06NFy7do1W9azZ08bc7127VpridZu3QAAAAAAIJyhu1ChQlKyZElp0aKF1K9f35bFihVLunXrFtZdAAAAAAAQUMI8pnvFihWSP39+ef/9923cdePGjWXVqlXuHh0AAAAAAIEQup955hmZNGmSHDt2TEaNGiWHDh2S5557TnLlyiWDBg2yquMAAAAAAOARqpcnTpzYpu3Slu+//vrLiqlpkTOdo/vFF18M7+4AAAAAAIixwh26veXMmVN69OhhBdR0nm2dlgsAAAAAADzklGGOlStXWnfzH374wQqqvfrqq9K8efOH3R0AAAAAAIEduo8ePSpTpkyxx759+6Rs2bIycuRIC9za7RwAAAAAADxE6K5Ro4YsXrxY0qRJI40aNZJmzZpJ7ty5w/pyAAAAAAACTphDd9y4ceX777+XWrVqSezYsd09KgAAAAAAAil0z549290jAQAAAAAghnmk6uUAAAAAAODeCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAARIV5uu9XUC0oKEgSJEggOXPmlOzZs0fEsQEAAAAAEFihu06dOhawg4ODfZY7y/RruXLl5KeffpKUKVNG5LECAAAAABCzu5cvWrRISpYsaV/Pnz9vD/2+VKlSMnfuXFm5cqWcPn1aOnXq5M4RAwAAAAAQU1u627VrJxMmTJCyZct6llWqVMm6lrdq1Up27Nghw4cPl2bNmkX0sQIAAAAAELNbuvfv3y/JkiW7a7kuO3DggH3/5JNPyn///RcxRwgAAAAAQKCE7uLFi0vnzp3l1KlTnmX6fZcuXazbudq7d69kzpw5Yo8UAAAAAICY3r184sSJUrt2bcmUKZMnWB85ckRy5MghP//8sz2/dOmS9OrVK+KPFgAAAACAmBy6c+fOLTt37pSFCxfKX3/95VlWpUoViRUrlqfCOQAAAAAAgS7coVtpuK5evbo9AAAAAABABIbuJUuW2OPkyZNy584dn3WTJk16mF0CAAAAABDjhDt09+vXT/r37y8lSpSQDBkySFBQkDtHBgAAAABAoIXu8ePHy5QpU+TNN99054gAAAAAAAjUKcNu3LghZcuWdedoAAAAAAAI5NDdokULmT59ujtHAwAAAABAIHcvv3btmkyYMEEWL14shQoVkrhx4/qsHzp0aEQeHwAAAAAAgRO6t27dKkWKFLHvt2/f7rOOomoAAAAAADxC6F62bFl4XwIAAAAAQEAK95huAAAAAAAQgS3ddevWtWnCkiVLZt/fz6xZs8L4owEAAAAAiNnCFLqTJ0/uGa+t3wMAAAAAgAgK3ZMnTw71ewAAAAAAEIFjuq9evSpXrlzxPP/7779l+PDhsnDhwvDuCgAAAACAGC3cobt27dry5Zdf2vfnzp2Tp556SoYMGWLLx40b58YxAgAAAAAQGKH7zz//lGeeeca+//777yV9+vTW2q1BfOTIkW4cIwAAAAAAgRG6tWt50qRJ7XvtUq7VzGPFiiWlS5e28A0AAAAAAB4ydOfMmVN++uknOXLkiCxYsECqVq1qy0+ePGlTigEAAAAAgIcM3b1795ZOnTpJtmzZpFSpUlKmTBlPq3fRokXDuzsAAAAAAAJ7yjBvL7/8spQrV06OHTsmhQsX9iyvVKmSvPTSSxF9fAAAAAAABE7oVlo8TR/qwoULsnTpUsmdO7fkyZMnoo8PAAAAAIDA6V7+6quvyujRoz1zdpcoUcKWFSpUSH744Qc3jhEAAAAAgMAI3StXrvRMGfbjjz9KcHCwzdet04V9+OGHbhwjAAAAAACBEbrPnz8vqVKlsu/nz58v9erVk0SJEknNmjVl79694Q7wL7zwgmTMmFGCgoKsKrq3Jk2a2HLvR/Xq1X22OXPmjDRs2NAqp6dIkUKaN28uly5d8tlm69atdqMgQYIEkjlzZhk8eHB43zYAAAAAAO6Hbg2t69atk8uXL1vodqYMO3v2rIXa8NB9aDG2MWPG3HMbDdlatM15fPPNNz7rNXDv2LFDFi1aJHPnzrUg36pVK896HXOux5g1a1bZuHGjfPrpp9K3b1+ZMGFCeN86AAAAAADuFlJr3769Bd0kSZJYkC1fvrwt17BbsGDBcO2rRo0a9rif+PHje4q2hbRr1y4L/n/88YeNLVejRo2S559/Xj777DNrQZ82bZrcuHFDJk2aJPHixZP8+fPL5s2bZejQoT7hHAAAAAAAv7d0v/POO9bSrSF29erVEivW/9tFjhw5XBnTvXz5ckmbNq1VR3/77bfl9OnTnnV6HNql3AncqnLlynZMv/32m2ebZ5991gK3o1q1arJnzx5rnQcAAAAAIEpNGaYh1zvoKh3THdG0a3ndunUle/bssn//funRo4e1jGuQjh07thw/ftwCubc4ceLYmHNdp/Srvt5bunTpPOtSpkx518+9fv26Pby7qAMAAAAA4Ero7tixowwYMEASJ05s39+PdtuOKPXr1/d8r13XdVqyJ554wlq/K1WqJG4ZOHCg9OvXz7X9AwAAAAACQ5hC96ZNm+TmzZue7+9Fq4u7Sbuwp0mTRvbt22ehW8d6nzx50mebW7duWUVzZxy4fj1x4oTPNs7ze40V7969u8/NBW3p1gJyAAAAAABEeOhetmxZqN9Htn/++cfGdGfIkMGelylTxuYI16rkxYsXt2VLly6VO3fuSKlSpTzb9OzZ024axI0b15ZppXMdIx5a13KneJs+AAAAAACI1EJqEUnn09ZK4vpQBw8etO8PHz5s6zp37izr16+XQ4cOyZIlS6R27dqSM2dOK4Sm8ubNa+O+W7ZsKb///rusWbNG2rZta93StXK5atCggRVR0/m7dWqxb7/9VkaMGPHAbvIAAAAAAERaIbVmzZqFaTutah5WGzZskAoVKnieO0G4cePGMm7cONm6datMnTrVWrM1ROt82zq23LsVWqcE06Ct3c21anm9evVk5MiRnvXJkyeXhQsXSps2baw1XLun9+7dm+nCAAAAAABRJ3RPmTLF5uUuWrSoBAcHR8gP1zm+77evBQsWPHAfWql8+vTp991GC7CtWrXqoY4RAAAAAADXQ7fOkf3NN99YF/CmTZvKG2+8YYEXAAAAAAA84pjuMWPGyLFjx6RLly4yZ84cq+b96quvWmt0RLV8AwAAAAAQsIXUdCz166+/btW/d+7cKfnz55d33nlHsmXLZoXPAAAAAADAQ4Zub1q0TOfl1lbu27dv85kCAAAAAPAoofv69es2rrtKlSqSK1cu2bZtm4wePdqm+EqSJEl4dgUAAAAAQIwX5kJq2o18xowZNpZbpw/T8K3TbwEAAAAAgEcM3ePHj5csWbJIjhw5ZMWKFfYIzaxZs8K6SwAAAAAAYrQwh+5GjRrZGG4AAAAAABDBoXvKlClh3RQAAAAAADxK9XIAAAAAAHB/hG4AAAAAAFxC6AYAAAAAwCWEbgAAAAAA/Bm6ixUrJmfPnrXv+/fvL1euXHHreAAAAAAACKzQvWvXLrl8+bJ9369fP7l06ZLbxwUAAAAAQGBMGVakSBFp2rSplCtXToKDg+Wzzz6TJEmShLpt7969I/oYAQAAAACIuaFb5+ju06ePzJ07V4KCguTXX3+VOHHufqmuI3QDAAAAABCO0J07d26ZMWOGfR8rVixZsmSJpE2bNiwvBQAAAAAgYIUpdHu7c+eOO0cCAAAAAECgh261f/9+GT58uBVYU/ny5ZN27drJE088EdHHBwAAAABA4MzTvWDBAgvZv//+uxQqVMgev/32m+TPn18WLVrkzlECAAAAABAILd3dunWTDh06yCeffHLX8q5du0qVKlUi8vgAAAAAAAiclm7tUt68efO7ljdr1kx27twZUccFAAAAAEDghe7HHntMNm/efNdyXUZFcwAAAAAAHqF7ecuWLaVVq1Zy4MABKVu2rC1bs2aNDBo0SDp27Bje3QEAAAAAEGOFO3R/8MEHkjRpUhkyZIh0797dlmXMmFH69u0r7733nhvHCAAAAABAYITuoKAgK6Smj4sXL9oyDeEAAAAAACAC5ul2ELYBAAAAAIjAQmoAAAAAACBsCN0AAAAAALiE0A0AAAAAQFQI3Tdv3pRKlSrJ3r173ToeAAAAAAACM3THjRtXtm7d6t7RAAAAAAAQyN3L33jjDZk4caI7RwMAAAAAQCBPGXbr1i2ZNGmSLF68WIoXLy6JEyf2WT906NCIPD4AAAAAAAIndG/fvl2KFStm3//1118+64KCgiLuyAAAAAAACLTQvWzZMneOBAAAAACAGOahpwzbt2+fLFiwQK5evWrPg4ODI/K4AAAAAAAIvNB9+vRpmzYsV65c8vzzz8uxY8dsefPmzeX999934xgBAAAAAAiM0N2hQwebOuzw4cOSKFEiz/LXXntN5s+fH9HHBwAAAABA4IzpXrhwoXUrz5Qpk8/yJ598Uv7++++IPDYAAAAAAAKrpfvy5cs+LdyOM2fOSPz48SPquAAAAAAACLzQ/cwzz8iXX37pM03YnTt3ZPDgwVKhQoWIPj4AAAAAAAKne7mGay2ktmHDBrlx44Z06dJFduzYYS3da9ascecoAQAAAAAIhJbuAgUKyF9//SXlypWT2rVrW3fzunXryqZNm+SJJ55w5ygBAAAAAAiElm6VPHly6dmzZ8QfDQAAAAAAgdzSrc6ePSufffaZzc2tjyFDhlj38vBauXKlvPDCC5IxY0YbG/7TTz/5rA8ODpbevXtLhgwZJGHChFK5cmXZu3evzzb6cxs2bCjJkiWTFClS2PFcunTJZ5utW7faWPQECRJI5syZrYs8AAAAAABRLnRrUM6WLZuMHDnSwrc+9Pvs2bPbuvDQrumFCxeWMWPGhLpew7Hue/z48fLbb79J4sSJpVq1anLt2jXPNhq4dUz5okWLZO7cuXYMrVq18qy/cOGCVK1aVbJmzSobN26UTz/9VPr27SsTJkwI71sHAAAAAMDd7uVt2rSR1157TcaNGyexY8e2Zbdv35Z33nnH1m3bti3M+6pRo4Y9QqOt3MOHD5devXrZ2HGlVdPTpUtnLeL169eXXbt2yfz58+WPP/6QEiVK2DajRo2S559/3lritQV92rRpVvBt0qRJEi9ePMmfP79s3rxZhg4d6hPOAQAAAADwe0v3vn375P333/cEbqXfd+zY0dZFlIMHD8rx48etS7n3WPJSpUrJunXr7Ll+1S7lTuBWun2sWLGsZdzZ5tlnn7XA7dDW8j179lgrPQAAAAAAUSZ0FytWzFqYQ9Jl2lU8omjgVtqy7U2fO+v0a9q0aX3Wx4kTR1KlSuWzTWj78P4ZIV2/ft26pXs/AAAAAABwpXu5FiJzvPfee9KuXTtr1S5durQtW79+vY3L/uSTTyQmGDhwoPTr18/fhwEAAAAACITQXaRIEasuruOsHV26dLlruwYNGth474iQPn16+3rixAmrXu7Q53o8zjYnT570ed2tW7esornzev2qr/HmPHe2Cal79+7WXd6hLd1a9RwAAAAAgAgP3Tq+OrJpNXQNxUuWLPGEbA2/Olb77bfftudlypSRc+fOWVXy4sWL27KlS5fKnTt3bOy3s43OKX7z5k2JGzeuLdNK57lz55aUKVOG+rPjx49vDwAAAAAAXA/dOt2WG3Q+be/iaxrutbK4jsnOkiWLtG/fXj788EN58sknLYR/8MEHVpG8Tp06tn3evHmlevXq0rJlS5tWTIN127ZtrbK5bue0vmtXcZ2/u2vXrrJ9+3YZMWKEDBs2zJX3BAAAAADAQ08Zpo4ePSqrV6+2rt3aquxNx3yH1YYNG6RChQqe506X7saNG8uUKVOsC7vO5a1Te2mLdrly5WyKsAQJEnheo1OCadCuVKmSVS2vV6+eze3tXfF84cKFNp2ZtoanSZNGevfuzXRhAAAAAADXBQV7D9QOAw3Db731lk3BlTp1ahvr7dlZUJAcOHBAYhrt1q7h/fz585IsWTJ/H060kK3bPH8fAmKoQ5/U9PchIIbivAW3cN4CgJgprDkx3C3d2sVbW4q12Ji2LAMAAAAAgNCFOzVfuXLFxkwTuAEAAAAAiODQrQXJvvvuu/C+DAAAAACAgBPu7uUDBw6UWrVqWUGzggULeqbhcgwdOjQijw8AAAAAgMAK3QsWLLB5rlXIQmoAAAAAAOAhQ/eQIUNk0qRJ0qRJk/C+FAAAAACAgBLuMd3x48eXp59+2p2jAQAAAAAgkEN3u3btZNSoUe4cDQAAAAAAgdy9/Pfff5elS5fK3LlzJX/+/HcVUps1a1ZEHh8AAAAAAIETulOkSCF169Z152gAAAAAAAjk0D158mR3jgQAAABAmGXrNo9PC6449ElNPll/jukGAAAAAAAutXRnz579vvNxHzhwILy7BAAAAAAgRgp36G7fvr3P85s3b8qmTZtk/vz50rlz54g8NgAAAAAAAit065RhoRkzZoxs2LAhIo4JAAAAAIAYIcLGdNeoUUN++OGHiNodAAAAAADRXoSF7u+//15SpUoVUbsDAAAAACDwupcXLVrUp5BacHCwHD9+XE6dOiVjx46N6OMDAAAAACBwQnedOnV8nseKFUsee+wxKV++vOTJkycijw0AAAAAgMAK3X369HHnSAAAAAAAiGEibEw3AAAAAAB4yJZu7UbuPZY7NLr+1q1bYd0lAAAAAAAxWphD948//njPdevWrZORI0fKnTt3Iuq4AAAAAAAInNBdu3btu5bt2bNHunXrJnPmzJGGDRtK//79I/r4AAAAAAAIrDHdR48elZYtW0rBggWtO/nmzZtl6tSpkjVr1og/QgAAAAAAAiF0nz9/Xrp27So5c+aUHTt2yJIlS6yVu0CBAu4dIQAAAAAAMb17+eDBg2XQoEGSPn16+eabb0Ltbg4AAAAAAB4idOvY7YQJE1ort3Yl10doZs2aFdZdAgAAAAAQo4U5dDdq1OiBU4YBAAAAAICHCN1TpkwJ66YAAAAAAOBhq5cDAAAAAIAHI3QDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAAEIihu2/fvhIUFOTzyJMnj2f9tWvXpE2bNpI6dWpJkiSJ1KtXT06cOOGzj8OHD0vNmjUlUaJEkjZtWuncubPcunXLD+8GAAAAABBo4kgUlz9/flm8eLHneZw4/3fIHTp0kHnz5sl3330nyZMnl7Zt20rdunVlzZo1tv727dsWuNOnTy9r166VY8eOSaNGjSRu3Ljy8ccf++X9AAAAAAACR5QP3RqyNTSHdP78eZk4caJMnz5dKlasaMsmT54sefPmlfXr10vp0qVl4cKFsnPnTgvt6dKlkyJFisiAAQOka9eu1ooeL148P7wjAAAAAECgiNLdy9XevXslY8aMkiNHDmnYsKF1F1cbN26UmzdvSuXKlT3batfzLFmyyLp16+y5fi1YsKAFbke1atXkwoULsmPHDj+8GwAAAABAIInSLd2lSpWSKVOmSO7cua1reL9+/eSZZ56R7du3y/Hjx62lOkWKFD6v0YCt65R+9Q7cznpn3b1cv37dHg4N6QAAAAAAxKjQXaNGDc/3hQoVshCeNWtWmTlzpiRMmNC1nztw4EAL+AAAAAAAxOju5d60VTtXrlyyb98+G+d948YNOXfunM82Wr3cGQOuX0NWM3eehzZO3NG9e3cbM+48jhw54sr7AQAAAADEbNEqdF+6dEn2798vGTJkkOLFi1sV8iVLlnjW79mzx8Z8lylTxp7r123btsnJkyc92yxatEiSJUsm+fLlu+fPiR8/vm3j/QAAAAAAIEZ1L+/UqZO88MIL1qX86NGj0qdPH4kdO7a8/vrrNkVY8+bNpWPHjpIqVSoLxu+++64Fba1crqpWrWrh+s0335TBgwfbOO5evXrZ3N4arAEAAAAACNjQ/c8//1jAPn36tDz22GNSrlw5mw5Mv1fDhg2TWLFiSb169azwmVYmHzt2rOf1GtDnzp0rb7/9toXxxIkTS+PGjaV///5+fFcAAAAAgEARpUP3jBkz7rs+QYIEMmbMGHvci7aS//LLLy4cHQAAAAAAMWhMNwAAAAAA0QmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHBJQIXuMWPGSLZs2SRBggRSqlQp+f333/19SAAAAACAGCxgQve3334rHTt2lD59+siff/4phQsXlmrVqsnJkyf9fWgAAAAAgBgqYEL30KFDpWXLltK0aVPJly+fjB8/XhIlSiSTJk3y96EBAAAAAGKoOBIAbty4IRs3bpTu3bt7lsWKFUsqV64s69atu2v769ev28Nx/vx5+3rhwoVIOuLo7871K/4+BMRQ/H8It3Degls4b8EtnLfgFs5b4fucgoOD77tdQITu//77T27fvi3p0qXzWa7Pd+/efdf2AwcOlH79+t21PHPmzK4eJ4AHSz6cTwlA9MJ5C0B0w3krfC5evCjJkycP7NAdXtoiruO/HXfu3JEzZ85I6tSpJSgoyK/Hhph3d0xv5hw5ckSSJUvm78MBgAfivAUguuG8BbdoC7cG7owZM953u4AI3WnSpJHYsWPLiRMnfJbr8/Tp09+1ffz48e3hLUWKFK4fJwKXBm5CN4DohPMWgOiG8xbccL8W7oAqpBYvXjwpXry4LFmyxKf1Wp+XKVPGr8cGAAAAAIi5AqKlW2l38caNG0uJEiXkqaeekuHDh8vly5etmjkAAAAAAG4ImND92muvyalTp6R3795y/PhxKVKkiMyfP/+u4mpAZNJhDDp3fMjhDAAQVXHeAhDdcN6CvwUFP6i+OQAAAAAAeCgBMaYbAAAAAAB/IHQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALiF0AwAAAIh27ty54/OcSZkQVRG6gQjGCR9AdD1vhbyABYCoLFas/xdlVqxYYV+DgoL8fERA6AjdQATSC1bnhH/48GE5evQony+AKB+49by1cOFCef/99+X8+fP+PiQACLMNGzZI7dq1ZeXKlXxqiLII3YALd1x79OghL7zwguTPn1+6d+8uW7Zs4XMGECVp4P7hhx+kfv36cvv2bbthCADRRapUqSRbtmyyfft2e06PHURFQcH0hQUemZ7gncD99ddfW9AeNGiQtXSPGTNGypYtK23btpUyZcrwaQOIUv7880+pUqWKDB48WJo3b+5ZfuXKFUmYMCHdNQFEyestb3r++vTTT63VO2vWrH45NuB+aOkGIoDzB2DdunXWqv3xxx9LgwYNpFOnTvLFF1/Y3deRI0fK+vXr+bwBRAnOPfc9e/ZIkSJFLHCfOXNGZsyYIbVq1ZISJUrIkCFD5MKFC/4+VADwud46cOCAXL9+3fOpvPbaa5IvXz6ZP3++PddeO0BUQugGIujiVYN1xYoVZcSIEXLq1CnPukqVKsnQoUNl586dMmrUKE+xDwDwZ9h2viZKlEiWLVtm5ykdFjN9+nTJnDmz1KhRQwYMGCBHjhzhFwXAr7y7jH///feSM2dOeeutt2Ty5Mm2TFu39ebhuHHj7Hns2LH9dqxAaAjdwEPyHpmhYyILFCgg06ZNk9SpU8uqVatk165dPsF72LBhsmTJElm6dCmfOQC/Fk3Tc1GXLl3k8uXLVoDoo48+kilTpkjRokWlT58+duGqXTVz5Mgh586d47cFIEq0cHfu3FlOnjwpEydOlJQpU0r79u2latWqMn78eGnTpo3cvHnT1gFRDWO6gUccU6Qn+Lhx43rWaSuRXsy+9NJL8u6770quXLk86zZu3Gh3YrkDC8BftGhaq1at5M0337RH8eLFbbmG6xQpUni204KQ2qKkFYHTp0/PLwyA324UqjVr1siLL74o8+bNk9KlS9uyv//+24bB6PWVNnbo9dXzzz8vU6dO5beFKIXQDTxC4B49erSN49bgrWOJevbsaQH8q6++smJqoQVvZ6wRwRtAZNMiQ9oqpIUeW7Zs6Vl+9epVK5qm5s6dKz/++KPMnj3bphHT1m8A8Ceti6NjuPVc1bt3b59rKb0G02szLVy7aNEiWb58uZ2/tEAkEFXQvRwI7/80/3/g7tatm/Tt21cyZcpkJ/vvvvvOCg9du3bNWo8++eQTO+mHNiaSwA3AHzZt2mTnKQ3cZ8+etZbsOnXqSLFixeR///uf1aM4ceKErdMLVwI3AH/TmRRmzZolXbt2lf3793tawJ1rKW3siB8/vnTs2NGK17788st281CvzZg+DFEFLd3AQ3Rx2rp1q12oTpgwQSpXruxpQdIum/HixbMuUPrHYNKkSRa89Y9FaFNcAEBk+umnn6Ru3bry2WefyZw5cyRJkiSSNm1aSZYsmRV63Lt3rxVR05uHug4AIpueh5588kn7/vPPP5d69epZ/QntTahdy7U2jt4Q9O556H2NNnDgQBtG88cffzDlIaIMUgDwAOXLl5fffvvN58R9+vRpm1rH+aOg9A+AXsjq9DoLFiywZc2aNbOLXP2jwN1WAP4q9uhd1FG7ZmqhtDx58kivXr2s6JBOc1ioUCEb1x0nThwCNwC/0KlV69evb2OytUja22+/LRcvXrTq5Bqmy5YtK9WrV7epDr2vrfQazTnn3bhxw7qh6+uAqCKOvw8AiMr0hK3TgGnxM2+5c+e21iEN19q6rbRlu3DhwtYt859//rlrX7R0A4gsTquP9rr5888/5d9//5VGjRrZNDs6LKZdu3ZW+dfRv39/68L5+OOP80sC4Df58+e3GjlayFGvwbQXYfbs2e2cpr1wtOVbr7uee+45K/KoNXOc850+9Fy3efNm+frrr60HDxBV0NIN3EfSpEmtVUjHCukdVu3WpLTbpQZsHQ85f/58z/Y6rkgvWhMnTsznCsAvnAtQHdZSs2ZNmx5Mz10aurUYkbZmO4F78eLFNr5bx3PPmDHDbiYCgD9oYTS97ipTpoxcunTJwvaWLVus5drpbah1dHRoX8mSJa23zuHDh316Iuo1mE7fSj0KRDWM6QbC4NatW1Yc7dtvv7WQrdV/9+3bJ02aNLH1GsD1D4BWLddCRFqsiGJpAPzZwv3qq69aIUcd5qLF0bSVSIfENGjQQN577z3bdvLkybJs2TKbp1tbmAAgsnmPzVZ6DaXPhw4dauO733jjDWvd1qEvDu1ROGzYMBk8eLDnest7XDcQ1RC6gVDs2LHDxg9pi7ae0LXwUJo0aay7k45/1HHaNWrUkIMHD1oLkXYzT5AggWTMmNHm6dYWb6YFAxAZtJZE6tSppWnTpp6bhF9++aW1EI0YMUIOHDhgBR91qIxekOp0YF26dJE2bdpYLx4d+6itSwDgz8Ct5yzthaPnpXTp0ln9HJ129dChQ9K4cWN56623bLt+/frZ8lSpUtlzrrcQHRC6gRD0Dqt2w9QTvJ7ox44dK7t27bJx3DpeW+ff1tYhJ3jryV4vZLUrlDN+SC96ve/IAoAbdMxjp06dLGTreUkLECk9d2kFcr15WKtWLcmWLZvdMNRumrpML2o1dOtraRkC4G96baXjsFXBggVtejAdt61FazVg61RhulzHbGuxNe1VSI9CRCekAiAEHQeklTG19UiD9KpVqyxw691YvQOrY7vVSy+9ZFPuVKlSxZ47gVu7NxG4AUQGbaHWaXT0/KPdL/UmYMOGDS1Ya5jWXjvHjx+3Qmnq77//lqeeesq6mmv3cwI3AH/w7gq+fPlyG4etFcu1O7k+12Ex48ePt2us0aNHy6BBg+Svv/6SRIkS2XAZDdwhu6UDURmhG/DidFEqVqyYtRxlyZJF1q5da5U0ncJDTvDWE321atVsOjEdz+3gIhZAZHAuOPU8pdXItYeNTq+j5yAdt610CkNt3daL1bx589rwF13/ySefMC0YAL9xrpW0Fo7eHNTWbB0Cow+9MThkyBC7kahD+HR4jHPjUIfv6WvpUYjohtANeN1xdboqlSpVSjZu3GiVfrV42vXr16Vt27aSIkUKn+CtXTapkAnAnxetGqy1oq92z9RlrVu3tuUavIsXL27zb+sF64cffmjbag0KrVcBAP5s4dYu41OmTLHGi86dO3u20euq999/33M+GzVqlA3n894HPQoR3TCmGwHPu3vS+fPn7Wvy5Mk9n0v79u1l9erVUq9ePRsDqd049Y5sx44dbToLxR1XAP64cJ07d65N9aUB+/nnn7fpc7R4mrYOaZdMrU+hNw1nz55tPXm0BSlHjhz8sgBECb/88osMHz7cWrt1asMiRYp41ul82zp8JmHChDZFKxCdEboR0LwDt7Zcr1y5UrZv3y7Nmze3cURPP/20revQoYMFb21N0sJF+odAx0lypxWAv2gxx9dff10++OADefnllyVXrly2/MiRI3YRq8FbC0HqdDsAEFXo+Gxt5db5ttWiRYvsnPXff//ZMp2G1aFjvJ944gnGbiPaI3QDInYnVU/0+odAK/5qFWDtSq7T6jiF0rSw2u7du63VaNKkSUwLBsBvdI7amjVrSsuWLW3oS0gavHV4jI6LnDlzpoVyAPA37Rn4+eefW49B7UL+6aef2vJff/1VxowZY1XJ9YahDovxRtE0RHeM6UbA0+6ZP/zwg3Vr0q6XWq1cW7ILFCggH3/8sYXr8uXL29Q63id9upQD8JebN2/acBjvFiHvsZLaK0cvaOPFi2fT7ACAPzjXTc75SXsINm3a1KqQ67zbOuxl6NChNmZb148bN05q164tixcvthZuB1XKEd0RuhHwMmTIYOMhNXBr8NYxkHoXVisCv/LKK9KvXz+5fPmytSo5J32KeACITM4Fq/bESZAggXXDPHbsmF24OiFcbxCqLVu22Fy2OsZbC6gxly0Af3Gum/744w+7zlJ63nrttdcskOuMC7qN9ibU6VqvXr0q69ats0K1QExC93IElNC6J+l0Ojoft7YI6d3VSpUqSY8ePWxd6dKl7eL2xRdftDuxAOAvCxcutKkMdXiLnq80VGvwnj9/vqRLl86z3XvvvWfhXLuXa0AHAH9as2aNPPPMM9aVXHvgOLRBQxs5tCeh3iDs1atXqNO4AjEBM8ojIAP30aNHbcyj0ovXVKlSWYG0AwcOyOOPP27LdVyRdm0aMGCA3YEFgMgyceJEKzTktHIr7YmTOnVqO2cpnZtbZ1PQG4UrVqyQOXPm2LQ7Ou+tjpckcAOICnSmlz59+shHH30kw4YN8yxPnDixzcGtNXR69+5txdS8EbgRk9C9HAHDCdx6J1Wn2NGQrVPn6JRg2qVJp6TQ59pqpOO1dXoK7eakXaD0tRTxABAZtPVHh7XoBagGaaebpY7h1huEjmrVqtl827pdnTp15LHHHrP1y5YtYxw3AL8I7VopY8aM1gNHh8ho+NYbiTrtqjNFqxZ61GlZ9QYiEFPRvRwB9QdgypQp1hKkXcW1O6ZOp3Po0CFp3LixTQv27bffWhVzHQ+pY7q1ZUnHSRK4AUQmnZJQu4/ruefHH3+0liKd+ksvXgcPHuwzhlv99ddfdvGqreApU6bklwUg0nlfK2kFcj0v6UwLTZo0kZIlS9pNwk8++cQerVu3tpCtFcu1V44WtNVQTpFaxFSEbgQMbTHS8Y/6B6FFixae5doNU8dKTps2TUqUKGHdyvUubJo0aWxb/gAAiCx67tGHnnv0fKWtP9rCvWTJErsxWLx4cRv/qGO2tQqwPvScpd3Oqe4LICrQxg2derVWrVqya9cuq42j3cg/+OADSZ8+vUydOtWmZNWbiNq1fOnSpXYT0XsGBiCmIXQjIBw8eFBy585tAdop1uEdposVKyb58uWTr7/+2uekTws3gMjknH/0JuHhw4flpZdesm7k2oKt5yNtOSpSpIjVpdAKwDomUtfpjUOnkjkA+Mvy5cut96C2XGtDhtJehdqTUK+1dFy3nqvOnj1rw/wyZ85MCzcCAmO6ESOFvFuqXTO1q3ibNm2sxUjvsDoXsdo6VKZMGbsTq7xfR8sRgMik558NGzZYd0wtOKQtQYsWLZL69evLypUrZdCgQZI3b145d+6cFRmKHz++FChQgMANIEq4cuWKVR3X3jeOd955x5Zr/YmuXbva+UqHwThDYfRazGkEAWIqqpcjRnKCs05PMX36dPu+SpUqNnZo27ZtdgGrF606XZi2eOv8kVoFGAD8ae/evdbVsmXLltKoUSO7eNXumFr8UVuJtMCjdjHX8d2vv/661K1bV3LlysUvDUCk07Ac2vWXLteCkErrTygtWqvL9PwWEg0cCASEbsRomzdvthYjLUTkBO9vvvlGVq9eLaVKlbILVr141Xm6tfsTAPird86ZM2essJCOezxx4oQt19ZsvYDV4K29dTSEP/XUU/L333/ziwLgN97D78aPH29juFWNGjWsh47WztHu407BRx0SkyFDBitiCwQiQjdi9B1XLY6mLUYarHV8kRO8dbnejd2xY4fNDblz5077w6Ct3gDgj+EwOt3Xl19+aTMnbNq0SdatW2frnSkL9WJVx3rrcBkN3wDgL07g1uF6H374oRV+1IfSnjkXLlyQsmXLWhjXHjparVy7lZcvX55fGgIShdQQ4+jdVL3L6k1P9l999ZU9tDCRWrx4sXUz14qaWuBDUTkTQGRxzjcaoJ0Wbb2Q1Xm2mzVrZhesWgVYC6cpZ72zPQD4kxaf1fm2f/31Vxv24k1nVdDW7n379tl5Tm8Wzpo1yxo4OIchEBG6EaPMnDlTGjZsKKtWrZLSpUv7rGvatKm1Ek2aNMmmsdCLVy1QpOMm9aJW/2gAQGQGbi3sqMNftMaEzqCgF6lp06a1c1OrVq3k6aeftuBduHBhfjEAohTtKaizw2iDhjMjTMhA7QyV0fMa83AjkNG9HDGqS7nOaast16+88or89ttvnotb9dZbb9kUFXXq1LEqwEq3/eKLL2wann///dcP7wBAINKLz59++sluAF6/fl1Onjxp4VvHa+tUYToMZsKECfL777/bha0WgASAqGT//v3Wkq00cOs1mQZuLVK7du1aW67DYvThFFijSjkCFaEbMaKIh47R1i7ierKfPXu2VfnVcK3B26lkrl2aunfvLoMHD5Zy5crZMl33/PPP2wXt448/7tf3AyBwaNfLvn37Sv/+/eV///ufzbOtYx9z585tYx51vQbvUaNGWdE07+l3AMCfnMaMihUr2thtvYGoLdzONdnp06etIKQO4/NGlXIEMkI3oi3n5K1dL3v16mVT7WgRDw3X2s1cq5NrK9LUqVOtu7le3GprdqdOnexOq1M0TYO3FvcAgMi4UNVzj56ntP6EM15b6fzbelNQ567Vm4h6Y7FatWrWYhSyTgUA+Fvt2rUlTZo0NvuLFoHUmWD27NljQ2OuXr0qFSpU8PchAlEGY7oRrWkLUc+ePW0qnZIlS961vnnz5vLzzz9LkiRJbModDd/O9BUAENk2btxoLdp9+vSRF154waYI++ijj3yCudaj0G7m2srtLHN67ACAv28c6vnol19+sQaMQoUKydtvvy27du2yXjm5cuWSBAkS2NSsFE0D/k8cr++BaHfy37BhgzRo0MACd2iVfSdOnCjvvvuunfi1FUnXO8U+ACCy6YXoihUr7OJUh7lowTSt+lu3bl3PxawOdUmRIoXPBS4ARKbQbvY5z7X+hBah1RZubdCYMmWKdSnXGhSZMmWSMmXK2HUY11vA/6GlG9FyDLdDu48nTZpUvvnmG58/ElqYaP369fLcc8/5bM80FQAik3NO0q6WCRMmtGXPPPOMzcn9ww8/yKuvvir//POPTQ+mlcq1yKN209R6FHny5OGXBcCv11vnz5+Xmzdv2rAXDdLLly+XqlWrWk8cLVAb2rWZ4noL8MWYbkQL3id17cJ05coV+/6JJ56Q7du3WwVN77uy//33nwwfPtxTPdPB3LYAIpOekxYsWGBjHLVYmlP4cevWrVadfPr06TaLgoZsHSqzZcsWawkncAPwB72Wcq63BgwYIK+99ppNZ9i2bVv57rvvpECBAtbQoYH7fsXRuN4CfNHSjSjPO0xrNUwdR6R/CLTquE4BpoWIcuTIIUOGDJHs2bPLtWvXbK7by5cv2xy4nPgB+PP8pRenOjWhthTpcJfGjRvbRauO7x40aJDkzJnTbixq90wt6pg4cWJ+YQD8Sq+3xo0bZ7VztJfOwIEDbU5u7UKuXcoBhA8DWxHlOYG7X79+1jKkY4d0SjClF7E6RlK7OunYbu0GpeOJ9AJWu5dr4L5X1ycAcPtGoX7Vm4Ba1VdbiHQs5IkTJ2yso/bamTNnjnTo0MHOUY899hi/EAB+d+DAAeuho7MoaLHHpUuXWg0d7VKugZux2kD4kUQQLeiYR71YHTFihNSoUUPSpUtny/XEnzlzZuuSqS3dOu+tzsWtd2K1eJquJ3ADiEwatPUiVVu3VYkSJWyebR0Go8u12q/avXu3vP/++9a1HAD8RRsnvOl107lz56Ro0aI2B7dODabXWM2aNbP6FDosRoM5gLCjpRvRgp78Dx8+bBXIldN6rVXI9Q+Aqlmz5l1FPKhSDiCy6bnHGaOthdG0e/nIkSMtfGutCe22eeHCBZtWR28maiAHAH9xGic2bdpk11l6DosXL56dt/Shw2Bat25t2+zcudPOW1pTR4f2AQgbWroR5e+4Ku0yrlXK58+fb8+dqb+Udi/XKsDOcwdjuQH4g557tMfN5s2brSt5ly5drAu5zset47i1wGOyZMmsq6YWgtQx3QDgT7/++qtUrFhRbty4YYFa6+b079/fhse88847to3WyunTp4/VztFpwQCEHYXUEKV4j7/++eef5fjx4zY+UqfT0but//77r7zxxhvSsGFD20bvxuofhrRp08pXX33l56MHAF8aurVq+dChQ2Xv3r12rtL6Ex9++CEfFYAoJX/+/Ba89Yag9iJ8++23reijVi7XMK6t3HpO0xZxHcJHzRwg7AjdiJI6deokU6dOtWlz9OSu89dqa7dOBaaPbNmyWbemZcuWWfE03Yau5ACiKp3ntmvXrjJ69GgrALlv3z7rvQMAkS3kHNoaqLU7ud4cnDdvnhWs1Xo5et7SITGrVq2ykJ07d25r/dbrLYqpAeFD6EaU8/3338t7771nVX21SrmO5+7cubOcOXNGnnzySXn88cftzmuaNGksiOsdWf4AAIgO1cwXL15s57GsWbP6+7AABJijR49KxowZPc937NhhrdsOLY5WsmRJ6datm113hQzl9wrtAB6M0I0oZ/DgwTJr1iy7s6onde1urt3MtZuTdmXSbuchcccVQHQJ3gAQ2bQC+bPPPmszJiithaPhWmdT0HoTOiuM9sLRlu1JkyZZ44YTyDl/AY+OQmqIMvSkrrTVWot06J1Vp2CazguplYC19VsLEYV8HV3LAURlBG4A/tSkSRN599137fvr169LuXLl5NNPP7UpWV9++WVp3ry5TbeqNXS00KO2gitt7OD8BTw6QjeiDOekXr16davo+9lnn9lzJ1Brd6YCBQrYndjQXgcAAIC7vfTSS9ZFfNiwYZ7CaHXq1LHpDXWGhcSJE0v58uVl5syZsnv3bunVq5eN6XaK2wJ4NMzTjSgnX758MnHiRGnZsqXNZVuvXj0L2v369ZMUKVJYETUAAACEj15H6TA9va7S1m0tjtaoUSN7aIu3FlLTxgwN24zbBiIOY7oRZem4br0bqyf/RIkS2VQ7y5cvZ5oKAACAB5g/f74VRkudOrW1XGu3cW3Vnjx5snzwwQfy2muvWb2cnDlzel6jc3HrtGBa7FFDN9OCARGD0I0oTQuo6clfu0EVL17cM8abMdwAAAChO3XqlNSqVUtOnz4tVapUsaC9fv16KVKkiK3XYmm9e/e24N2mTRubhjVk0TSqlAMRh9CNaIU7rgAAAA+mxdAqVKggFy9elF9//dXGbGuh2gQJEniCd58+faR+/fo2pC9Xrlx8rIBLGNONaIWCHgAAAPfmtFbrNZPO/pIhQwarXL5o0SJ7rtXL48ePL82aNbNtdGx3lixZCN2Ai2jpBgAAAGJYb0AdjqdjtPft2yft27e3rubLli2zObm9LV26VJ577jkKpwEuInQDAAAAMSRwa7dynR5MW7u1SJqOzV63bp10795dzp0752nxfvPNN6V06dI2plsxhhtwD6EbAAAAiKa8i5/17dtXvv/+e7ly5YoF7549e1q41lCuwbtHjx6yadMmKViwoPz777+yd+9emxUGgLsI3QAAAEA0p4F77NixMm3aNMmWLZv069dPpk+fLmPGjLGpwTScHz58WH744Qfrdq4t3zobDC3cgPsopAYAAABEYxs3bpQVK1bIjBkzpGLFijJv3jx71KxZ07qPa9fzt956y+bf7tixo+d1BG4gcvxftQUAAAAAUZ62WnvT4mjVq1eXp59+2gqj6RRgAwcOtBBeuXJla+keOnToXfuJHTt2JB41ELjoXg4AAABEw6Jp+/fvlyRJkljodpY3adJEEiVKJCNGjLDx2q1bt7aWcJ2fe+XKlZ7x3wAiDy3dAAAAQDThBG4tila7dm3Jnz+/dOnSxYK12rJliyROnNgC99WrV+XUqVM23nvVqlUWuEO2kgNwH2O6AQAAgGjUwv3dd9/Jl19+KaNHj5atW7fKL7/8YvNx9+rVS5o2bSqdOnWSCxcuyObNm+XmzZvW9TxkpXMAkYfu5QAAAEA0oV3EtQJ54cKFpVmzZrZs7ty5MmTIEEmZMqXUr19f/vvvP5k9e7Y8/vjjMn78eGv1pmga4D+EbgAAACAaOH78uJQrV866jOuUYO3bt/esmzNnjo3jTpEihXTo0MGKqjlu3bpl04MB8A/GdAMAAADRQPr06WXWrFn2VbuUb9u2zbPuhRdesLC9Z88eC+AO7VJO4Ab8i5ZuAAAAIBrRYmk6drtEiRLSrl07K6bmWLt2rZQqVYrpwIAohNANAAAARDObNm2SFi1aSPHixa2beb58+XzWM4YbiDoI3QAAAEA0Dd5vvfWWZM2aVQYPHizZs2f39yEBCAVjugEAAIBoqGjRojZtWNKkSS14A4iaaOkGAAAAojFn/m3vubwBRB2EbgAAACCGBG8AUQ+3wgAAAIBojsANRF2EbgAAAAAAXELoBgAAAADAJYRuAAAAAABcQugGAAAAAMAlhG4AAAAAAFxC6AYAAAAAwCWEbgAAYpAmTZrY1EEhH/v27XvkfU+ZMkVSpEgRIccJAECgiOPvAwAAABGrevXqMnnyZJ9ljz32WJT6mG/evClx48b192EAAOA6WroBAIhh4sePL+nTp/d5xI4dW37++WcpVqyYJEiQQHLkyCH9+vWTW7dueV43dOhQKViwoCROnFgyZ84s77zzjly6dMnWLV++XJo2bSrnz5/3tJ737dvX1un3P/30k88xaIu4toyrQ4cO2TbffvutPPfcc/bzp02bZuu++OILyZs3ry3LkyePjB07NhI/KQAA3EdLNwAAAWDVqlXSqFEjGTlypDzzzDOyf/9+adWqla3r06ePfY0VK5atz549uxw4cMBCd5cuXSwIly1bVoYPHy69e/eWPXv22PZJkiQJ1zF069ZNhgwZIkWLFvUEb93f6NGjbdmmTZukZcuWFvobN27swqcAAEDkI3QDABDDzJ071ycQ16hRQ86ePWuh1wmz2tI9YMAAC9VO6G7fvr3nNdmyZZMPP/xQWrdubaE7Xrx4kjx5cmux1pbzh6H7r1u3rue5/lwN4c4yDfs7d+6Uzz//nNANAIgxCN0AAMQwFSpUkHHjxnmea8txoUKFZM2aNfLRRx95lt++fVuuXbsmV65ckUSJEsnixYtl4MCBsnv3brlw4YJ1Pfde/6hKlCjh+f7y5cvW2t68eXNr3Xboz9RwDwBATEHoBgAghtGQnTNnTp9lOjZbx3B7tzQ7tKu3jruuVauWvP322xbMU6VKJatXr7ZQfOPGjfuGbm39Dg4OvqtQWmjH5X086n//+5+UKlXKZzsdfw4AQExB6AYAIABoATUdix0yjDs2btwod+7cse7eOrZbzZw502cb7WKureMhaWX0Y8eOeZ7v3bvXWsfvJ126dJIxY0YbO96wYcOHfFcAAER9hG4AAAKAFizTluwsWbLIyy+/bMF6y5Ytsn37dhu7rWFcW6dHjRolL7zwgnVFHz9+vM8+dJy3tlAvWbJEChcubK3f+qhYsaIVQytTpoyF8q5du4ZpOjBteX/vvfesO7lOc3b9+nXZsGGDjT/v2LGji58GAACRhynDAAAIANWqVbMCawsXLpSSJUtK6dKlZdiwYZI1a1ZbryFapwwbNGiQFChQwCqL6/hub1rBXAurvfbaa9a6PXjwYFuureM6xZhWRW/QoIF06tQpTGPAW7RoYVOG6ZziOlWZTiem04xpQTUAAGKKoOCQg7AAAAAAAECEoKUbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAAAQd/x/P5/iBoNgNZAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize missing values to understand their distribution\n",
    "# This helps us decide on an imputation strategy\n",
    "\n",
    "# Get counts of missing values and keep only features with missing data\n",
    "missing_counts = data_manual.isnull().sum()\n",
    "missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "missing_counts.plot(kind='bar')\n",
    "plt.title('Missing Values by Feature')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273c556",
   "metadata": {},
   "source": [
    "### Step 2: Split the Data\n",
    "\n",
    "**Important**: We must split the data BEFORE any preprocessing to avoid data leakage. This is a common mistake that can lead to overly optimistic model performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3eab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 39073 samples\n",
      "Test set size: 9769 samples\n",
      "\n",
      "Training set shape: (39073, 13)\n",
      "Test set shape: (9769, 13)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Separate features (X) from target variable (y)\n",
    "X = data_manual.drop(columns=[target])  # All columns except 'class'\n",
    "y = data_manual[target]  # Just the 'class' column\n",
    "\n",
    "# Step 2: Split into training (80%) and test (20%) sets\n",
    "# Why split BEFORE preprocessing? To prevent data leakage!\n",
    "# If we preprocess first, information from test set could leak into training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42,    # For reproducibility\n",
    "    stratify=y          # Keep same class distribution in train and test\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9babcec2",
   "metadata": {},
   "source": [
    "### Step 3: Impute Missing Values\n",
    "\n",
    "Now we'll handle missing values separately for numerical and categorical features. We fit the imputers on the training data and transform both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features after imputation:\n",
      "Training set: (39073, 5)\n",
      "Test set: (9769, 5)\n",
      "Missing values in training numerical features: 0\n"
     ]
    }
   ],
   "source": [
    "# Impute (fill) missing values in NUMERICAL features\n",
    "# Strategy: Use the MEAN value from the training data\n",
    "# Why mean? Common choice for numerical data that's roughly normally distributed\n",
    "\n",
    "# Step 1: Create and FIT the imputer on TRAINING data only\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "X_train_num = num_imputer.fit_transform(X_train[numerical_features])\n",
    "\n",
    "# Step 2: TRANSFORM the test data using the imputer fitted on training data\n",
    "# Important: We use transform() NOT fit_transform() on test data!\n",
    "X_test_num = num_imputer.transform(X_test[numerical_features])\n",
    "\n",
    "# Step 3: Convert numpy arrays back to DataFrames for easier handling\n",
    "X_train_num = pd.DataFrame(X_train_num, columns=numerical_features, index=X_train.index)\n",
    "X_test_num = pd.DataFrame(X_test_num, columns=numerical_features, index=X_test.index)\n",
    "\n",
    "# Verify imputation worked\n",
    "print(\"Numerical features after imputation:\")\n",
    "print(f\"Training set: {X_train_num.shape}\")\n",
    "print(f\"Test set: {X_test_num.shape}\")\n",
    "print(f\"Missing values in training numerical features: {X_train_num.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68516439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features after imputation:\n",
      "Training set: (39073, 7)\n",
      "Test set: (9769, 7)\n",
      "Missing values in training categorical features: 0\n"
     ]
    }
   ],
   "source": [
    "# Impute (fill) missing values in CATEGORICAL features\n",
    "# Strategy: Use the MOST FREQUENT value (mode) from the training data\n",
    "# Why most frequent? For categories, using the most common value is sensible\n",
    "\n",
    "# Step 1: Create and FIT the imputer on TRAINING data only\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_train_cat = cat_imputer.fit_transform(X_train[categorical_features])\n",
    "\n",
    "# Step 2: TRANSFORM the test data (don't fit again!)\n",
    "X_test_cat = cat_imputer.transform(X_test[categorical_features])\n",
    "\n",
    "# Step 3: Convert back to DataFrames\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns=categorical_features, index=X_train.index)\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns=categorical_features, index=X_test.index)\n",
    "\n",
    "# Verify imputation worked\n",
    "print(\"Categorical features after imputation:\")\n",
    "print(f\"Training set: {X_train_cat.shape}\")\n",
    "print(f\"Test set: {X_test_cat.shape}\")\n",
    "print(f\"Missing values in training categorical features: {X_train_cat.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc414d7b",
   "metadata": {},
   "source": [
    "### Step 4: Scale Numerical Features\n",
    "\n",
    "We'll standardize numerical features to have mean=0 and standard deviation=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b9913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features after scaling:\n",
      "\n",
      "Means (should be close to 0):\n",
      "age              -0.0\n",
      "education-num    -0.0\n",
      "capital-gain      0.0\n",
      "capital-loss      0.0\n",
      "hours-per-week   -0.0\n",
      "dtype: float64\n",
      "\n",
      "Standard deviations (should be close to 1):\n",
      "age               1.000013\n",
      "education-num     1.000013\n",
      "capital-gain      1.000013\n",
      "capital-loss      1.000013\n",
      "hours-per-week    1.000013\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Scale numerical features using StandardScaler\n",
    "# What it does: Transforms each feature to have mean=0 and standard deviation=1\n",
    "# Why? Many ML algorithms perform better when features are on the same scale\n",
    "# Formula: z = (x - mean) / standard_deviation\n",
    "\n",
    "# Step 1: Create and FIT scaler on TRAINING data\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "\n",
    "# Step 2: TRANSFORM test data using training statistics\n",
    "# Critical: Use the SAME mean and std from training, don't calculate new ones!\n",
    "X_test_num_scaled = scaler.transform(X_test_num)\n",
    "\n",
    "# Step 3: Convert back to DataFrames\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    X_train_num_scaled, \n",
    "    columns=numerical_features, \n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    X_test_num_scaled, \n",
    "    columns=numerical_features, \n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Verify scaling worked correctly\n",
    "print(\"Numerical features after scaling:\")\n",
    "print(\"\\nMeans (should be close to 0):\")\n",
    "print(X_train_num_scaled.mean().round(10))\n",
    "print(\"\\nStandard deviations (should be close to 1):\")\n",
    "print(X_train_num_scaled.std().round(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fffafd3",
   "metadata": {},
   "source": [
    "### Step 5: Encode Categorical Features\n",
    "\n",
    "We'll use One-Hot Encoding to convert categorical variables into binary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categorical features: 7\n",
      "Encoded features: 83\n",
      "\n",
      "First 10 encoded feature names:\n",
      "['workclass_ Federal-gov' 'workclass_ Local-gov' 'workclass_ Never-worked'\n",
      " 'workclass_ Private' 'workclass_ Self-emp-inc'\n",
      " 'workclass_ Self-emp-not-inc' 'workclass_ State-gov'\n",
      " 'workclass_ Without-pay' 'marital-status_ Divorced'\n",
      " 'marital-status_ Married-AF-spouse']\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encode categorical features\n",
    "# What it does: Converts each category into a binary (0/1) column\n",
    "# Example: 'color': ['red', 'blue'] becomes 'color_red': [1,0] and 'color_blue': [0,1]\n",
    "# Why? ML models need numerical input, can't process text directly\n",
    "\n",
    "# Step 1: Create and FIT encoder on TRAINING data\n",
    "# sparse_output=False: Return dense array instead of sparse matrix\n",
    "# handle_unknown='ignore': If test has new categories, fill with all zeros\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train_cat)\n",
    "\n",
    "# Step 2: TRANSFORM test data (using categories learned from training)\n",
    "X_test_cat_encoded = encoder.transform(X_test_cat)\n",
    "\n",
    "# Step 3: Get the generated feature names\n",
    "# Example: 'workclass' with value 'Private' becomes 'workclass_Private'\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "print(f\"Original categorical features: {len(categorical_features)}\")\n",
    "print(f\"Encoded features: {len(encoded_feature_names)}\")\n",
    "print(f\"\\nFirst 10 encoded feature names:\")\n",
    "print(encoded_feature_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ada46",
   "metadata": {},
   "source": [
    "### Step 6: Combine All Features\n",
    "\n",
    "Now we need to combine the scaled numerical features and the encoded categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85eb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training set shape: (39073, 88)\n",
      "Final test set shape: (9769, 88)\n",
      "\n",
      "Total features: 88\n",
      "  - Numerical features: 5\n",
      "  - Encoded categorical features: 83\n"
     ]
    }
   ],
   "source": [
    "# Combine numerical and categorical features into single arrays\n",
    "# np.hstack = horizontal stack (combine columns side-by-side)\n",
    "# Result: [numerical_features | encoded_categorical_features]\n",
    "\n",
    "X_train_manual = np.hstack([X_train_num_scaled, X_train_cat_encoded])\n",
    "X_test_manual = np.hstack([X_test_num_scaled, X_test_cat_encoded])\n",
    "\n",
    "print(f\"Final training set shape: {X_train_manual.shape}\")\n",
    "print(f\"Final test set shape: {X_test_manual.shape}\")\n",
    "print(f\"\\nTotal features: {X_train_manual.shape[1]}\")\n",
    "print(f\"  - Numerical features: {len(numerical_features)}\")\n",
    "print(f\"  - Encoded categorical features: {len(encoded_feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d7241",
   "metadata": {},
   "source": [
    "### Step 7: Train and Evaluate Model\n",
    "\n",
    "Now let's train a Logistic Regression model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305680f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Preprocessing Approach Results:\n",
      "==================================================\n",
      "Training Accuracy: 0.8520\n",
      "Test Accuracy: 0.8522\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.88      0.93      0.91      7431\n",
      "        >50K       0.74      0.59      0.66      2338\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.85      0.85      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model on our preprocessed data\n",
    "# max_iter=1000: Maximum iterations for the solver to converge\n",
    "# random_state=42: For reproducible results\n",
    "\n",
    "# Step 1: Create and train the model\n",
    "lr_manual = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_manual.fit(X_train_manual, y_train)\n",
    "\n",
    "# Step 2: Make predictions on both training and test sets\n",
    "y_train_pred = lr_manual.predict(X_train_manual)\n",
    "y_test_pred = lr_manual.predict(X_test_manual)\n",
    "\n",
    "# Step 3: Evaluate performance\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Manual Preprocessing Approach Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28fae4",
   "metadata": {},
   "source": [
    "### Problems with the Manual Approach\n",
    "\n",
    "While the manual approach works, it has several issues:\n",
    "\n",
    "1. **Code Repetition**: We have to repeat similar steps for train and test data\n",
    "2. **Error Prone**: Easy to accidentally fit on test data or forget to transform\n",
    "3. **Hard to Maintain**: Changes require updating multiple places\n",
    "4. **Not Reproducible**: Difficult to apply the same preprocessing to new data\n",
    "5. **Memory Intensive**: We keep creating intermediate DataFrames\n",
    "6. **No Guarantee of Consistency**: Parameters learned from training data must be carefully tracked\n",
    "\n",
    "**Let's see how pipelines solve all these problems!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e9525",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 â€” Pipeline Approach (The Right Way!)\n",
    "\n",
    "Now let's rebuild the entire workflow using scikit-learn's `Pipeline` and `ColumnTransformer`. This approach is cleaner, more maintainable, and prevents data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb0f5d9",
   "metadata": {},
   "source": [
    "### Understanding Pipelines\n",
    "\n",
    "A **Pipeline** chains multiple steps into a single estimator. The key benefits are:\n",
    "\n",
    "- **Convenience**: Apply all steps with a single `fit()` and `predict()` call\n",
    "- **Safety**: Ensures transformers are fit only on training data\n",
    "- **Reproducibility**: Easy to save and load the entire preprocessing + model\n",
    "- **Grid Search**: Can tune hyperparameters across all steps together\n",
    "\n",
    "A **ColumnTransformer** allows applying different transformations to different columns, which is perfect for handling numerical and categorical features separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60b926",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Fresh Data\n",
    "\n",
    "Let's start fresh with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67291d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline approach - Data prepared\n",
      "Training set: (39073, 13)\n",
      "Test set: (9769, 13)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for pipeline approach (starting fresh)\n",
    "# We'll do the same preprocessing, but in a cleaner, automated way\n",
    "\n",
    "# Step 1: Copy and clean the data\n",
    "data_pipeline = data.copy()\n",
    "data_pipeline = data_pipeline.replace(' ?', np.nan)  # Replace missing value indicator\n",
    "\n",
    "# Step 2: Separate features and target\n",
    "X_pipeline = data_pipeline.drop(columns=[target])\n",
    "y_pipeline = data_pipeline[target]\n",
    "\n",
    "# Step 3: Split into train and test (using same parameters for fair comparison)\n",
    "X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe = train_test_split(\n",
    "    X_pipeline, y_pipeline, \n",
    "    test_size=0.2, \n",
    "    random_state=42,  # Same random state = same split\n",
    "    stratify=y_pipeline\n",
    ")\n",
    "\n",
    "print(f\"Pipeline approach - Data prepared\")\n",
    "print(f\"Training set: {X_train_pipe.shape}\")\n",
    "print(f\"Test set: {X_test_pipe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacde090",
   "metadata": {},
   "source": [
    "### Step 2: Build Preprocessing Pipelines\n",
    "\n",
    "We'll create separate pipelines for numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfb56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipelines created:\n",
      "\n",
      "Numerical Pipeline:\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler())])\n",
      "\n",
      "Categorical Pipeline:\n",
      "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('encoder',\n",
      "                 OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessing pipelines for each feature type\n",
    "# A Pipeline chains multiple steps: each step's output becomes the next step's input\n",
    "\n",
    "# Numerical Pipeline: \n",
    "# Step 1: Impute missing values with mean\n",
    "# Step 2: Scale to mean=0, std=1\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical Pipeline:\n",
    "# Step 1: Impute missing values with most frequent category\n",
    "# Step 2: One-hot encode categories into binary columns\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "print(\"Preprocessing pipelines created:\")\n",
    "print(f\"\\nNumerical Pipeline:\")\n",
    "print(numerical_pipeline)\n",
    "print(f\"\\nCategorical Pipeline:\")\n",
    "print(categorical_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0f1b9",
   "metadata": {},
   "source": [
    "### Step 3: Combine with ColumnTransformer\n",
    "\n",
    "The `ColumnTransformer` applies different pipelines to different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a637122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer created:\n",
      "ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer', SimpleImputer()),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['age', 'education-num', 'capital-gain',\n",
      "                                  'capital-loss', 'hours-per-week']),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('encoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                sparse_output=False))]),\n",
      "                                 ['workclass', 'marital-status', 'occupation',\n",
      "                                  'relationship', 'race', 'sex',\n",
      "                                  'native-country'])])\n"
     ]
    }
   ],
   "source": [
    "# Combine both pipelines using ColumnTransformer\n",
    "# ColumnTransformer applies different transformations to different columns\n",
    "# Format: (name, transformer, columns)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),      # Apply numerical_pipeline to numerical features\n",
    "        ('cat', categorical_pipeline, categorical_features)   # Apply categorical_pipeline to categorical features\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified (we've specified all of them)\n",
    ")\n",
    "\n",
    "print(\"ColumnTransformer created:\")\n",
    "print(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701e470",
   "metadata": {},
   "source": [
    "### Step 4: Create End-to-End Pipeline\n",
    "\n",
    "Now we'll create a complete pipeline that includes both preprocessing and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Pipeline:\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer()),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['age', 'education-num',\n",
      "                                                   'capital-gain',\n",
      "                                                   'capital-loss',\n",
      "                                                   'hours-per-week']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('encoder',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  ['workclass',\n",
      "                                                   'marital-status',\n",
      "                                                   'occupation', 'relationship',\n",
      "                                                   'race', 'sex',\n",
      "                                                   'native-country'])])),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(max_iter=1000, random_state=42))])\n",
      "\n",
      "============================================================\n",
      "Pipeline Structure:\n",
      "============================================================\n",
      "\n",
      "Step: preprocessor\n",
      "  Type: ColumnTransformer\n",
      "  Transformers: 2\n",
      "\n",
      "Step: classifier\n",
      "  Type: LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# Create a FULL end-to-end pipeline that does EVERYTHING:\n",
    "# 1. Preprocessing (imputation, scaling, encoding)\n",
    "# 2. Model training and prediction\n",
    "\n",
    "# This is the power of pipelines: one object handles the entire workflow!\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # All the preprocessing steps\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))  # The model\n",
    "])\n",
    "\n",
    "print(\"Complete Pipeline:\")\n",
    "print(full_pipeline)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pipeline Structure:\")\n",
    "print(\"=\"*60)\n",
    "for step_name, step in full_pipeline.steps:\n",
    "    print(f\"\\nStep: {step_name}\")\n",
    "    print(f\"  Type: {type(step).__name__}\")\n",
    "    if hasattr(step, 'transformers'):\n",
    "        print(f\"  Transformers: {len(step.transformers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c0593",
   "metadata": {},
   "source": [
    "### Step 5: Train the Pipeline\n",
    "\n",
    "With a pipeline, training is just one line of code! The pipeline will:\n",
    "1. Fit the imputers on training data\n",
    "2. Transform the training data with the fitted imputers\n",
    "3. Fit the scalers/encoders on the transformed training data\n",
    "4. Transform the training data again\n",
    "5. Fit the classifier on the final transformed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c208f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline trained successfully!\n",
      "\n",
      "The pipeline has learned:\n",
      "  - How to impute missing values (from training data)\n",
      "  - How to scale numerical features (from training data)\n",
      "  - Which categories exist (from training data)\n",
      "  - The logistic regression coefficients\n"
     ]
    }
   ],
   "source": [
    "# Train the pipeline - just one line!\n",
    "full_pipeline.fit(X_train_pipe, y_train_pipe)\n",
    "\n",
    "print(\"Pipeline trained successfully!\")\n",
    "print(\"\\nThe pipeline has learned:\")\n",
    "print(\"  - How to impute missing values (from training data)\")\n",
    "print(\"  - How to scale numerical features (from training data)\")\n",
    "print(\"  - Which categories exist (from training data)\")\n",
    "print(\"  - The logistic regression coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fcca0",
   "metadata": {},
   "source": [
    "### Step 6: Make Predictions\n",
    "\n",
    "Making predictions is also just one line! The pipeline automatically applies all preprocessing steps using the parameters learned from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "647cfbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Approach Results:\n",
      "==================================================\n",
      "Training Accuracy: 0.8520\n",
      "Test Accuracy: 0.8522\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.88      0.93      0.91      7431\n",
      "        >50K       0.74      0.59      0.66      2338\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.85      0.85      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions - also just one line!\n",
    "y_train_pred_pipe = full_pipeline.predict(X_train_pipe)\n",
    "y_test_pred_pipe = full_pipeline.predict(X_test_pipe)\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy_pipe = accuracy_score(y_train_pipe, y_train_pred_pipe)\n",
    "test_accuracy_pipe = accuracy_score(y_test_pipe, y_test_pred_pipe)\n",
    "\n",
    "print(\"Pipeline Approach Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Accuracy: {train_accuracy_pipe:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_pipe:.4f}\")\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test_pipe, y_test_pred_pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef400e",
   "metadata": {},
   "source": [
    "### Step 7: Compare Results\n",
    "\n",
    "Let's verify that both approaches give the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad1ad8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Comparison:\n",
      "============================================================\n",
      "Approach  Training Accuracy  Test Accuracy\n",
      "  Manual           0.851995       0.852185\n",
      "Pipeline           0.851995       0.852185\n",
      "\n",
      "============================================================\n",
      "âœ“ Both approaches produce identical results!\n",
      "âœ“ But the pipeline approach is cleaner, safer, and more maintainable.\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Approach': ['Manual', 'Pipeline'],\n",
    "    'Training Accuracy': [train_accuracy, train_accuracy_pipe],\n",
    "    'Test Accuracy': [test_accuracy, test_accuracy_pipe]\n",
    "})\n",
    "\n",
    "print(\"Results Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ Both approaches produce identical results!\")\n",
    "print(\"âœ“ But the pipeline approach is cleaner, safer, and more maintainable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f585ed80",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Advanced Pipeline Features\n",
    "\n",
    "Let's explore some powerful features of pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5ef38",
   "metadata": {},
   "source": [
    "### 1. Accessing Pipeline Components\n",
    "\n",
    "You can access individual steps in the pipeline to inspect their learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01ddd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned scaling parameters for numerical features:\n",
      "============================================================\n",
      "age                  - Mean:      38.70, Std:      13.74\n",
      "education-num        - Mean:      10.08, Std:       2.57\n",
      "capital-gain         - Mean:    1057.47, Std:    7332.41\n",
      "capital-loss         - Mean:      89.95, Std:     408.62\n",
      "hours-per-week       - Mean:      40.46, Std:      12.42\n",
      "\n",
      "\n",
      "Number of categories per feature:\n",
      "============================================================\n",
      "workclass            - 8 categories\n",
      "marital-status       - 7 categories\n",
      "occupation           - 14 categories\n",
      "relationship         - 6 categories\n",
      "race                 - 5 categories\n",
      "sex                  - 2 categories\n",
      "native-country       - 41 categories\n",
      "\n",
      "\n",
      "Example - Categories in 'workclass':\n",
      "[' Federal-gov' ' Local-gov' ' Never-worked' ' Private' ' Self-emp-inc'\n",
      " ' Self-emp-not-inc' ' State-gov' ' Without-pay']\n"
     ]
    }
   ],
   "source": [
    "# Access and inspect the learned parameters from the pipeline\n",
    "# This shows us what the pipeline learned during training\n",
    "\n",
    "# Access the preprocessor step\n",
    "preprocessor_fitted = full_pipeline.named_steps['preprocessor']\n",
    "\n",
    "# Navigate to the numerical transformer and get the scaler\n",
    "numerical_transformer = preprocessor_fitted.named_transformers_['num']\n",
    "scaler_fitted = numerical_transformer.named_steps['scaler']\n",
    "\n",
    "# Display the learned mean and standard deviation for each numerical feature\n",
    "print(\"Learned scaling parameters for numerical features:\")\n",
    "print(\"=\" * 60)\n",
    "for feature, mean, scale in zip(numerical_features, scaler_fitted.mean_, scaler_fitted.scale_):\n",
    "    print(f\"{feature:20s} - Mean: {mean:10.2f}, Std: {scale:10.2f}\")\n",
    "\n",
    "# Navigate to the categorical transformer and get the encoder\n",
    "categorical_transformer = preprocessor_fitted.named_transformers_['cat']\n",
    "encoder_fitted = categorical_transformer.named_steps['encoder']\n",
    "\n",
    "# Display the number of categories found in each categorical feature\n",
    "print(\"\\n\\nNumber of categories per feature:\")\n",
    "print(\"=\" * 60)\n",
    "for feature, categories in zip(categorical_features, encoder_fitted.categories_):\n",
    "    print(f\"{feature:20s} - {len(categories)} categories\")\n",
    "        \n",
    "# Show an example of the actual categories for one feature\n",
    "print(\"\\n\\nExample - Categories in 'workclass':\")\n",
    "print(encoder_fitted.categories_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce9d1a",
   "metadata": {},
   "source": [
    "### 2. Predicting on New Data\n",
    "\n",
    "One of the biggest advantages of pipelines is that you can easily apply the same preprocessing to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2065b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New person data:\n",
      "                                  0\n",
      "age                              35\n",
      "workclass                   Private\n",
      "education-num                    13\n",
      "marital-status   Married-civ-spouse\n",
      "occupation           Prof-specialty\n",
      "relationship                Husband\n",
      "race                          White\n",
      "sex                            Male\n",
      "capital-gain                      0\n",
      "capital-loss                      0\n",
      "hours-per-week                   40\n",
      "native-country        United-States\n",
      "\n",
      "============================================================\n",
      "Prediction:  >50K\n",
      "Probability of <=50K: 0.4689\n",
      "Probability of >50K: 0.5311\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate how easy it is to make predictions on completely new data\n",
    "# The pipeline automatically applies ALL preprocessing steps!\n",
    "\n",
    "# Create a sample data point representing a new person\n",
    "new_person = pd.DataFrame([{\n",
    "    'age': 35,\n",
    "    'workclass': ' Private',\n",
    "    'education-num': 13,\n",
    "    'marital-status': ' Married-civ-spouse',\n",
    "    'occupation': ' Prof-specialty',\n",
    "    'relationship': ' Husband',\n",
    "    'race': ' White',\n",
    "    'sex': ' Male',\n",
    "    'capital-gain': 0,\n",
    "    'capital-loss': 0,\n",
    "    'hours-per-week': 40,\n",
    "    'native-country': ' United-States'\n",
    "}])\n",
    "\n",
    "print(\"New person data:\")\n",
    "print(new_person.T)  # Transpose for better display\n",
    "\n",
    "# Make prediction - pipeline handles all preprocessing automatically!\n",
    "# It will: impute if needed, scale numerics, encode categoricals, then predict\n",
    "prediction = full_pipeline.predict(new_person)\n",
    "prediction_proba = full_pipeline.predict_proba(new_person)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Prediction: {prediction[0]}\")\n",
    "print(f\"Probability of <=50K: {prediction_proba[0][0]:.4f}\")\n",
    "print(f\"Probability of >50K: {prediction_proba[0][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b11b3",
   "metadata": {},
   "source": [
    "### 3. Saving and Loading Pipelines\n",
    "\n",
    "Pipelines can be easily saved and loaded using joblib or pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca24bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved to 'income_prediction_pipeline.pkl'\n",
      "Pipeline loaded successfully!\n",
      "\n",
      "Prediction from loaded pipeline:  >50K\n",
      "âœ“ Loaded pipeline works perfectly!\n"
     ]
    }
   ],
   "source": [
    "# Save and load pipelines for deployment\n",
    "# This is crucial for production: save once, load anywhere!\n",
    "import joblib\n",
    "\n",
    "# Save the ENTIRE pipeline (preprocessing + model) to a file\n",
    "# This includes all learned parameters: imputation values, scaling factors, categories, coefficients\n",
    "joblib.dump(full_pipeline, 'income_prediction_pipeline.pkl')\n",
    "print(\"Pipeline saved to 'income_prediction_pipeline.pkl'\")\n",
    "\n",
    "# Load the pipeline back from disk\n",
    "# Now you can use this in a web app, API, or different environment\n",
    "loaded_pipeline = joblib.load('income_prediction_pipeline.pkl')\n",
    "print(\"Pipeline loaded successfully!\")\n",
    "\n",
    "# Verify the loaded pipeline works exactly like the original\n",
    "test_prediction = loaded_pipeline.predict(new_person)\n",
    "print(f\"\\nPrediction from loaded pipeline: {test_prediction[0]}\")\n",
    "print(\"âœ“ Loaded pipeline works perfectly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae178f4",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "Pipelines integrate seamlessly with cross-validation and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e9ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "This will try different combinations of preprocessing and model parameters\n",
      "Total combinations: 6\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      "============================================================\n",
      "Grid Search Complete!\n",
      "============================================================\n",
      "Best parameters: {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'preprocessor__num__imputer__strategy': 'mean'}\n",
      "Best cross-validation score: 0.8509\n",
      "Test set score: 0.8522\n",
      "\n",
      "============================================================\n",
      "Grid Search Complete!\n",
      "============================================================\n",
      "Best parameters: {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'preprocessor__num__imputer__strategy': 'mean'}\n",
      "Best cross-validation score: 0.8509\n",
      "Test set score: 0.8522\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with GridSearchCV and Pipelines\n",
    "# GridSearchCV tries different parameter combinations and picks the best one\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid to search\n",
    "# Format: 'stepname__substep__parameter': [values to try]\n",
    "# We can tune BOTH preprocessing AND model parameters!\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['mean', 'median'],  # Try different imputation strategies\n",
    "    'classifier__C': [0.1, 1.0, 10.0],  # Try different regularization strengths\n",
    "    'classifier__penalty': ['l2']  # Keep L2 regularization\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "# cv=3: Use 3-fold cross-validation\n",
    "# n_jobs=-1: Use all CPU cores\n",
    "grid_search = GridSearchCV(\n",
    "    full_pipeline,  # The entire pipeline to tune\n",
    "    param_grid,     # Parameters to try\n",
    "    cv=3,           # 3-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,      # Parallel processing\n",
    "    verbose=1       # Show progress\n",
    ")\n",
    "\n",
    "print(\"Starting Grid Search...\")\n",
    "print(\"This will try different combinations of preprocessing and model parameters\")\n",
    "print(f\"Total combinations: {len(param_grid['preprocessor__num__imputer__strategy']) * len(param_grid['classifier__C'])}\")\n",
    "\n",
    "# Fit grid search - this trains multiple models and picks the best\n",
    "# For each combination, it does 3-fold CV, so total fits = combinations Ã— 3\n",
    "grid_search.fit(X_train_pipe, y_train_pipe)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Grid Search Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test set score: {grid_search.score(X_test_pipe, y_test_pipe):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d53aee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Best Practices\n",
    "\n",
    "Let's recap what we've learned about preprocessing and pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb98508",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "#### Manual Preprocessing\n",
    "âœ— **Pros:**\n",
    "- Easy to understand step-by-step\n",
    "- Good for learning the concepts\n",
    "- More control over each step\n",
    "\n",
    "âœ— **Cons:**\n",
    "- Error-prone (easy to introduce data leakage)\n",
    "- Lots of repetitive code\n",
    "- Hard to maintain and update\n",
    "- Difficult to deploy to production\n",
    "- Parameters must be manually tracked\n",
    "\n",
    "#### Pipeline Approach\n",
    "âœ“ **Pros:**\n",
    "- **Prevents data leakage** by design\n",
    "- **Clean and concise** code\n",
    "- **Easy to maintain** and update\n",
    "- **Reproducible** - can apply to new data easily\n",
    "- **Production-ready** - just save and load\n",
    "- **Integrates with cross-validation** and hyperparameter tuning\n",
    "- **Guarantees consistency** between training and prediction\n",
    "\n",
    "âœ“ **Cons:**\n",
    "- Requires understanding of the pipeline API\n",
    "- Slightly less transparent (abstraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822c74c",
   "metadata": {},
   "source": [
    "### Best Practices for Data Preprocessing\n",
    "\n",
    "1. **Always split data BEFORE preprocessing** to avoid data leakage\n",
    "2. **Use pipelines** for any non-trivial preprocessing workflow\n",
    "3. **Use ColumnTransformer** when you have different feature types\n",
    "4. **Fit transformers only on training data**, then transform both train and test\n",
    "5. **Save your pipelines** for deployment and reproducibility\n",
    "6. **Document your preprocessing choices** (why you chose mean vs median, etc.)\n",
    "7. **Test on new data** to ensure your pipeline generalizes\n",
    "8. **Use cross-validation** to validate your preprocessing choices\n",
    "9. **Version your pipelines** along with your models\n",
    "10. **Monitor for data drift** in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91490056",
   "metadata": {},
   "source": [
    "### Common Pitfalls to Avoid\n",
    "\n",
    "#### âŒ Data Leakage\n",
    "```python\n",
    "# WRONG: Scaling before splitting\n",
    "scaler.fit(X)  # Uses ALL data including test set!\n",
    "X_scaled = scaler.transform(X)\n",
    "X_train, X_test = train_test_split(X_scaled)\n",
    "\n",
    "# CORRECT: Split first, then fit on training only\n",
    "X_train, X_test = train_test_split(X)\n",
    "scaler.fit(X_train)  # Only uses training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "#### âŒ Inconsistent Preprocessing\n",
    "```python\n",
    "# WRONG: Different preprocessing for train and test\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.fit_transform(X_test)  # Fitting again!\n",
    "\n",
    "# CORRECT: Fit once, transform both\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)  # Just transform\n",
    "```\n",
    "\n",
    "#### âŒ Forgetting Preprocessing Steps\n",
    "```python\n",
    "# WRONG: Easy to forget a step\n",
    "prediction = model.predict(new_data)  # Forgot to scale!\n",
    "\n",
    "# CORRECT: Pipeline handles everything\n",
    "prediction = pipeline.predict(new_data)  # Automatically scales\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494db0a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "Try these exercises to test your understanding:\n",
    "\n",
    "### Exercise 1: Modify the Pipeline\n",
    "Create a new pipeline that uses:\n",
    "- Median imputation for numerical features instead of mean\n",
    "- `MinMaxScaler` instead of `StandardScaler`\n",
    "- Compare the results with the original pipeline\n",
    "\n",
    "### Exercise 2: Add Feature Engineering\n",
    "Extend the pipeline to:\n",
    "- Create a new feature: `capital-diff = capital-gain - capital-loss`\n",
    "- Create age groups: `young (<30)`, `middle (30-60)`, `senior (>60)`\n",
    "- Add these features before the model\n",
    "\n",
    "### Exercise 3: Try Different Models\n",
    "Replace the Logistic Regression with:\n",
    "- Random Forest Classifier\n",
    "- Gradient Boosting Classifier\n",
    "- Support Vector Machine\n",
    "Compare their performance\n",
    "\n",
    "### Exercise 4: Handle Unknown Categories\n",
    "Test what happens when new data contains categories not seen during training:\n",
    "- Create a sample with a fake country or occupation\n",
    "- See how `handle_unknown='ignore'` handles it\n",
    "- Try `handle_unknown='error'` to see the difference\n",
    "\n",
    "### Exercise 5: Feature Selection in Pipeline\n",
    "Add a feature selection step:\n",
    "- Use `SelectKBest` or `SelectFromModel`\n",
    "- Place it after preprocessing but before the classifier\n",
    "- Find the optimal number of features using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beed184",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- [scikit-learn Pipeline Documentation](https://scikit-learn.org/stable/modules/compose.html)\n",
    "- [ColumnTransformer Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)\n",
    "- [Preprocessing Guide](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "\n",
    "### Further Reading\n",
    "- **Why pipelines matter**: They prevent data leakage and make ML workflows reproducible\n",
    "- **Production ML**: Pipelines are essential for deploying models to production\n",
    "- **MLOps**: Version control for pipelines using DVC, MLflow, or similar tools\n",
    "\n",
    "### Next Steps\n",
    "1. Learn about custom transformers (make your own preprocessing steps)\n",
    "2. Explore `make_pipeline()` for simpler pipeline creation\n",
    "3. Study `FeatureUnion` for parallel feature processing\n",
    "4. Practice with different datasets and preprocessing strategies\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You now understand both the manual and pipeline approaches to data preprocessing. Always prefer pipelines in real projects - your future self will thank you! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
