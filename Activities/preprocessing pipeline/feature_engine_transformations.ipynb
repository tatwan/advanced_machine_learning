{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-engine: 7 Essential Transformations for ML Students\n",
    "\n",
    "This notebook demonstrates 5–7 important feature-engine transformations that every machine learning student should know. We use the Titanic dataset (via seaborn) to illustrate transformations on both numerical and categorical variables. Each transformation includes a short explanation and a runnable example.\n",
    "\n",
    "Transformations covered:\n",
    "1. Mean/Median imputation for numerical variables (MeanMedianImputer)\n",
    "2. Categorical imputation for missing categorical values (CategoricalImputer)\n",
    "3. Rare label encoding to group infrequent categories (RareLabelEncoder)\n",
    "4. One-hot encoding for categorical expansion (OneHotEncoder)\n",
    "5. Equal-frequency discretisation / binning (EqualFrequencyDiscretiser)\n",
    "6. Log transformation to reduce skew (LogTransformer)\n",
    "7. Scaling numerical features (StandardScalerWrapper)\n",
    "\n",
    "All transformers are from the feature-engine library and are sklearn-compatible, so they can be included inside sklearn Pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!uv pip install -q feature-engine seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import MeanMedianImputer, CategoricalImputer\n",
    "from feature_engine.encoding import RareLabelEncoder, OneHotEncoder\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
    "from feature_engine.transformation import LogTransformer\n",
    "from feature_engine.scaling import MeanNormalizationScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "survived",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pclass",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fare",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "embarked",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "deck",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "ref": "b436555d-b373-4155-9ce0-a82201d5ffb0",
       "rows": [
        [
         "0",
         "0",
         "3",
         "male",
         "22.0",
         "7.25",
         "S",
         null
        ],
        [
         "1",
         "1",
         "1",
         "female",
         "38.0",
         "71.2833",
         "C",
         "C"
        ],
        [
         "2",
         "1",
         "3",
         "female",
         "26.0",
         "7.925",
         "S",
         null
        ],
        [
         "3",
         "1",
         "1",
         "female",
         "35.0",
         "53.1",
         "S",
         "C"
        ],
        [
         "4",
         "0",
         "3",
         "male",
         "35.0",
         "8.05",
         "S",
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age     fare embarked deck\n",
       "0         0       3    male  22.0   7.2500        S  NaN\n",
       "1         1       1  female  38.0  71.2833        C    C\n",
       "2         1       3  female  26.0   7.9250        S  NaN\n",
       "3         1       1  female  35.0  53.1000        S    C\n",
       "4         0       3    male  35.0   8.0500        S  NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "df = df[['survived','pclass','sex','age','fare','embarked','deck']].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look: the dataset contains numerical columns (age, fare), categorical columns (sex, embarked, deck), and missing values. We'll demonstrate transformations on a subset of these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Mean/Median imputation for numerical variables (MeanMedianImputer)\n",
    "\n",
    "When numerical features have missing values, replacing them with the mean or median is a simple baseline strategy. Median is robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "74126856-f643-4c1d-a95c-27e182a5ff53",
       "rows": [
        [
         "count",
         "714.0"
        ],
        [
         "mean",
         "29.69911764705882"
        ],
        [
         "std",
         "14.526497332334042"
        ],
        [
         "min",
         "0.42"
        ],
        [
         "50%",
         "28.0"
        ],
        [
         "max",
         "80.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.699118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.526497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age\n",
       "count  714.000000\n",
       "mean    29.699118\n",
       "std     14.526497\n",
       "min      0.420000\n",
       "50%     28.000000\n",
       "max     80.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_imputer = MeanMedianImputer(imputation_method='median', variables=['age'])\n",
    "df_imputed = num_imputer.fit_transform(df)\n",
    "df[['age']].describe().loc[['count','mean','std','min','50%','max']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that missing values in 'age' were replaced by the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), np.int64(177))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed['age'].isna().sum(), df['age'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Categorical imputation (CategoricalImputer)\n",
    "\n",
    "Categorical features sometimes have missing values. One option is to replace them with a string such as 'Missing' so that the model can learn from the presence of missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ba1e3e00-d562-4d56-b607-eb4cf399aff7",
       "rows": [
        [
         "embarked",
         "0"
        ],
        [
         "deck",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "embarked    0\n",
       "deck        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_imputer = CategoricalImputer(fill_value='Missing', variables=['embarked','deck'])\n",
    "df_cat_imputed = cat_imputer.fit_transform(df)\n",
    "df_cat_imputed[['embarked','deck']].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Rare label encoding (RareLabelEncoder)\n",
    "\n",
    "Rare categories (very infrequent) may create noisy features. RareLabelEncoder groups categories that appear in a small fraction of observations into a single label (e.g., 'Rare')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "deck",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "proportion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a57b4aa8-0cc8-442b-87e7-dcc99fb793f8",
       "rows": [
        [
         "Missing",
         "0.7721661054994389"
        ],
        [
         "Rare",
         "0.10886644219977554"
        ],
        [
         "C",
         "0.06621773288439955"
        ],
        [
         "B",
         "0.052749719416386086"
        ],
        [
         "A",
         "0.0"
        ],
        [
         "D",
         "0.0"
        ],
        [
         "E",
         "0.0"
        ],
        [
         "F",
         "0.0"
        ],
        [
         "G",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "deck\n",
       "Missing    0.772166\n",
       "Rare       0.108866\n",
       "C          0.066218\n",
       "B          0.052750\n",
       "A          0.000000\n",
       "D          0.000000\n",
       "E          0.000000\n",
       "F          0.000000\n",
       "G          0.000000\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate with 'embarked' (though it has few categories) and 'deck' which has a lot of NAs and many categories\n",
    "rare_enc = RareLabelEncoder(tol=0.05, n_categories=1, variables=['deck','embarked'])\n",
    "df_rare = rare_enc.fit_transform(df_cat_imputed)\n",
    "df_rare['deck'].value_counts(normalize=True).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) One-hot encoding (OneHotEncoder)\n",
    "\n",
    "Convert categorical variables into numerical columns via one-hot encoding. feature-engine's OneHotEncoder returns a DataFrame and allows dropping the last level to avoid collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "survived",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pclass",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fare",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deck",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "sex_male",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "embarked_S",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "embarked_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "embarked_Q",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "28e5c2b0-8622-42c0-b2bc-c1de7becc41a",
       "rows": [
        [
         "0",
         "0",
         "3",
         "22.0",
         "7.25",
         "Missing",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "1",
         "1",
         "1",
         "38.0",
         "71.2833",
         "C",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "2",
         "1",
         "3",
         "26.0",
         "7.925",
         "Missing",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "3",
         "1",
         "1",
         "35.0",
         "53.1",
         "C",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "4",
         "0",
         "3",
         "35.0",
         "8.05",
         "Missing",
         "1",
         "1",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>deck</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age     fare     deck  sex_male  embarked_S  embarked_C  \\\n",
       "0         0       3  22.0   7.2500  Missing         1           1           0   \n",
       "1         1       1  38.0  71.2833        C         0           0           1   \n",
       "2         1       3  26.0   7.9250  Missing         0           1           0   \n",
       "3         1       1  35.0  53.1000        C         0           1           0   \n",
       "4         0       3  35.0   8.0500  Missing         1           1           0   \n",
       "\n",
       "   embarked_Q  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(drop_last=True, variables=['sex','embarked'])\n",
    "df_ohe = ohe.fit_transform(df_rare)\n",
    "df_ohe.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Equal-frequency discretisation (EqualFrequencyDiscretiser)\n",
    "\n",
    "Discretisation (binning) transforms continuous variables into ordinal bins. Equal-frequency bins try to make bins with (roughly) the same number of observations.\n",
    "Binning can help models that benefit from ordinal categories or to capture non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['fare_bin'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m disc = EqualFrequencyDiscretiser(q=\u001b[32m4\u001b[39m, variables=[\u001b[33m'\u001b[39m\u001b[33mfare\u001b[39m\u001b[33m'\u001b[39m], return_object=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m df_disc = disc.fit_transform(df_ohe)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdf_disc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfare\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfare_bin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.head(\u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['fare_bin'] not in index\""
     ]
    }
   ],
   "source": [
    "disc = EqualFrequencyDiscretiser(q=4, variables=['fare'], return_object=True)\n",
    "df_disc = disc.fit_transform(df_ohe)\n",
    "df_disc[['fare','fare_bin']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: return_object=True returns bins as strings (like '(0.0, 7.91]') — useful when you want to one-hot encode the bins later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Log transformation (LogTransformer)\n",
    "\n",
    "Apply a log transform to reduce skew in positive-valued variables (e.g., fare). feature-engine's LogTransformer handles zero/negative values by adding an offset if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some variables contain zero or negative values, can't apply log",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m log_t = LogTransformer(variables=[\u001b[33m'\u001b[39m\u001b[33mfare\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_log = \u001b[43mlog_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df[[\u001b[33m'\u001b[39m\u001b[33mfare\u001b[39m\u001b[33m'\u001b[39m]].describe().loc[[\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/sklearn/base.py:894\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    879\u001b[39m         warnings.warn(\n\u001b[32m    880\u001b[39m             (\n\u001b[32m    881\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    890\u001b[39m         )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/feature_engine/transformation/log.py:135\u001b[39m, in \u001b[36mLogTransformer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# check contains zero or negative values\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (X[\u001b[38;5;28mself\u001b[39m.variables_] <= \u001b[32m0\u001b[39m).any().any():\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    136\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSome variables contain zero or negative values, can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt apply log\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m     )\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Some variables contain zero or negative values, can't apply log"
     ]
    }
   ],
   "source": [
    "log_t = LogTransformer(variables=['fare'])\n",
    "df_log = log_t.fit_transform(df)\n",
    "df[['fare']].describe().loc[['mean','std','min','max']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show original vs log transformed distribution (basic comparison using summary stats):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = df['fare'].dropna()\n",
    "trans = log_t.transform(df)['fare']\n",
    "pd.DataFrame({'original_mean':orig.mean(), 'original_std':orig.std(),\n",
    "              'log_mean':trans.mean(), 'log_std':trans.std()}, index=[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Scaling numerical features (StandardScalerWrapper)\n",
    "\n",
    "Standardisation (zero mean, unit variance) is a common preprocessing step, especially for algorithms that are distance-based or use regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m scaler = MeanNormalizationScaler(variables=[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mfare\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_scaled = scaler.fit_transform(\u001b[43mdf_log\u001b[49m)\n\u001b[32m      3\u001b[39m df_scaled[[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mfare\u001b[39m\u001b[33m'\u001b[39m]].describe().loc[[\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[31mNameError\u001b[39m: name 'df_log' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = MeanNormalizationScaler(variables=['age','fare'])\n",
    "df_scaled = scaler.fit_transform(df_log)\n",
    "df_scaled[['age','fare']].describe().loc[['mean','std']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together: a simple end-to-end Pipeline\n",
    "\n",
    "Below is a single sklearn Pipeline that chains several feature-engine transformers. Feature-engine transformers are compatible with sklearn Pipelines and operate on pandas DataFrames (returning DataFrames), which makes it convenient to build sequential transformations that act on different variables.\n",
    "\n",
    "Pipeline steps (example):\n",
    "- Impute numeric missing values (age)\n",
    "- Log transform fare\n",
    "- Scale numerical features\n",
    "- Impute categorical missing values\n",
    "- Rare label encode\n",
    "- One-hot encode selected categoricals\n",
    "- Discretise fare into equal-frequency bins (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some variables contain zero or negative values, can't apply log",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m pipeline = Pipeline([\n\u001b[32m      2\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mnum_imputer\u001b[39m\u001b[33m'\u001b[39m, MeanMedianImputer(imputation_method=\u001b[33m'\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m'\u001b[39m, variables=[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m])),\n\u001b[32m      3\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mlog_fare\u001b[39m\u001b[33m'\u001b[39m, LogTransformer(variables=[\u001b[33m'\u001b[39m\u001b[33mfare\u001b[39m\u001b[33m'\u001b[39m])),\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# ('discretiser', EqualFrequencyDiscretiser(q=4, variables=['fare'], return_object=True)),\u001b[39;00m\n\u001b[32m     10\u001b[39m ])\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Fit pipeline (transformers that need only X will be fit with X)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m df_transformed = pipeline.transform(df)\n\u001b[32m     15\u001b[39m df_transformed.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/sklearn/pipeline.py:655\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m     )\n\u001b[32m    654\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/sklearn/pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/sklearn/base.py:894\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    879\u001b[39m         warnings.warn(\n\u001b[32m    880\u001b[39m             (\n\u001b[32m    881\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    890\u001b[39m         )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/MyWork/Teach/repos/adv_ml_ds/dev1/lib/python3.12/site-packages/feature_engine/transformation/log.py:135\u001b[39m, in \u001b[36mLogTransformer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# check contains zero or negative values\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (X[\u001b[38;5;28mself\u001b[39m.variables_] <= \u001b[32m0\u001b[39m).any().any():\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    136\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSome variables contain zero or negative values, can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt apply log\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m     )\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Some variables contain zero or negative values, can't apply log"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('num_imputer', MeanMedianImputer(imputation_method='median', variables=['age'])),\n",
    "    ('log_fare', LogTransformer(variables=['fare'])),\n",
    "    ('scaler', MeanNormalizationScaler(variables=['age','fare'])),\n",
    "    ('cat_imputer', CategoricalImputer(fill_value='Missing', variables=['embarked','deck'])),\n",
    "    ('rare_encoder', RareLabelEncoder(tol=0.05, n_categories=1, variables=['deck','embarked'])),\n",
    "    ('ohe', OneHotEncoder(drop_last=True, variables=['sex','embarked'])),\n",
    "    # Optional: discretise fare to bins (uncomment if desired)\n",
    "    # ('discretiser', EqualFrequencyDiscretiser(q=4, variables=['fare'], return_object=True)),\n",
    "])\n",
    "\n",
    "# Fit pipeline (transformers that need only X will be fit with X)\n",
    "pipeline.fit(df)\n",
    "df_transformed = pipeline.transform(df)\n",
    "df_transformed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes and teaching tips\n",
    "- Show students how each transformer stores state (e.g., median used for imputation, categories identified as rare). Examine transformer attributes (e.g., num_imputer.imputer_dict_).\n",
    "- Emphasize the difference between transformers that need the target (e.g., some OrdinalEncoders that order by target) and those that don't.\n",
    "- Teach the importance of fitting transformers only on training data and applying to test data to avoid data leakage.\n",
    "- Demonstrate how to save pipelines (joblib.dump) and reuse them in production.\n",
    "\n",
    "This notebook introduced seven practical transformations from feature-engine. Students can extend the pipeline with additional feature-engine tools such as variable extractors, polynomial features (via sklearn), or decision-tree-based discretisers for supervised binning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: inspect what median was used for 'age'\n",
    "pipeline.named_steps['num_imputer'].imputer_dict_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: show the categories mapped to 'Rare' by the RareLabelEncoder\n",
    "pipeline.named_steps['rare_encoder'].encoder_dict_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
