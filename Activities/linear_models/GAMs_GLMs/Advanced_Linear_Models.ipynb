{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ac5b4b",
   "metadata": {},
   "source": [
    "\n",
    "# Advanced Linear Models: GLMs, GAMs, and Interaction Terms\n",
    "\n",
    "**Author:** Machine Learning Class Materials\n",
    "\n",
    "In this notebook, we will explore some advanced topics in linear models that go beyond the standard Linear and Logistic Regression. We will delve into **Generalized Linear Models (GLMs)**, **Generalized Additive Models (GAMs)**, and the concept of **Interaction Terms**. These models provide greater flexibility and allow us to model a wider range of data and relationships.\n",
    "\n",
    "After completing activities on Linear Regression and Logistic Regression, this notebook will help you understand how to extend these basic models to handle more complex scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5c983",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Overview\n",
    "\n",
    "Linear models are fundamental tools in machine learning and statistics. However, they have limitations:\n",
    "\n",
    "- **Linear Regression** assumes a linear relationship between predictors and the response, and that the response is normally distributed.\n",
    "- **Logistic Regression** is designed for binary classification problems.\n",
    "\n",
    "What happens when we need to model:\n",
    "- Count data (e.g., number of events)?\n",
    "- Non-linear relationships between predictors and response?\n",
    "- Situations where the effect of one variable depends on another?\n",
    "\n",
    "This is where **GLMs**, **GAMs**, and **Interaction Terms** come into play.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ea75b",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Generalized Linear Models (GLMs)\n",
    "\n",
    "### 2.1 What are GLMs?\n",
    "\n",
    "Generalized Linear Models (GLMs) are a flexible generalization of ordinary linear regression. They allow for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a **link function** and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n",
    "\n",
    "### 2.2 Components of a GLM\n",
    "\n",
    "GLMs are composed of three main components:\n",
    "\n",
    "| Component | Description | Examples |\n",
    "|-----------|-------------|----------|\n",
    "| **Random Component** | The probability distribution of the response variable | Gaussian, Poisson, Binomial, Gamma |\n",
    "| **Systematic Component** | The linear predictor: η = β₀ + β₁X₁ + ... + βₚXₚ | Linear combination of predictors |\n",
    "| **Link Function** | A function that links the expected value of the response to the linear predictor | Identity (linear), Log (Poisson), Logit (logistic) |\n",
    "\n",
    "### 2.3 Common GLM Families\n",
    "\n",
    "Different types of response variables require different probability distributions:\n",
    "\n",
    "- **Gaussian (Normal)**: Continuous data (standard linear regression)\n",
    "- **Poisson**: Count data (number of events)\n",
    "- **Binomial**: Binary or proportion data (logistic regression)\n",
    "- **Gamma**: Positive continuous data with constant coefficient of variation\n",
    "\n",
    "### 2.4 Example: Poisson Regression\n",
    "\n",
    "Poisson regression is used when the response variable represents count data. The link function is the natural logarithm, which ensures that predicted values are always positive.\n",
    "\n",
    "**Use Case:** Predicting the number of executions based on socioeconomic factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb14e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/statsmodels/statsmodels/main/statsmodels/datasets/cpunish/cpunish.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6aa058",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data for GLM\n",
    "X = df[['INCOME', 'PERPOVERTY', 'PERBLACK', 'VC100k96', 'SOUTH', 'DEGREE']]\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "y = df['EXECUTIONS']\n",
    "\n",
    "# Fit a Poisson GLM\n",
    "poisson_model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(poisson_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e0b93",
   "metadata": {},
   "source": [
    "\n",
    "### 2.5 Interpreting the Results\n",
    "\n",
    "In the Poisson regression output:\n",
    "\n",
    "- **Coefficients**: The coefficients are on the log scale. To interpret them, we need to exponentiate them. For example, if the coefficient for INCOME is 0.0003, then exp(0.0003) ≈ 1.0003, meaning a one-unit increase in INCOME is associated with a 0.03% increase in the expected count of executions.\n",
    "\n",
    "- **P-values**: Indicate whether each predictor is statistically significant.\n",
    "\n",
    "- **Deviance**: Measures the goodness of fit. Lower deviance indicates a better fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0425d54",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Generalized Additive Models (GAMs)\n",
    "\n",
    "### 3.1 What are GAMs?\n",
    "\n",
    "Generalized Additive Models (GAMs) are an extension of GLMs where the linear predictor is replaced by the sum of smooth functions of the predictors. This allows for more flexible, non-linear relationships between the predictors and the response variable.\n",
    "\n",
    "### 3.2 Mathematical Formulation\n",
    "\n",
    "Instead of a strict linear relationship:\n",
    "\n",
    "**GLM:** g(E[Y]) = β₀ + β₁X₁ + β₂X₂ + ... + βₚXₚ\n",
    "\n",
    "**GAM:** g(E[Y]) = β₀ + f₁(X₁) + f₂(X₂) + ... + fₚ(Xₚ)\n",
    "\n",
    "where f(X) are smooth functions (often represented by splines).\n",
    "\n",
    "### 3.3 Advantages of GAMs\n",
    "\n",
    "- **Flexibility**: Can capture complex non-linear patterns without specifying the exact functional form.\n",
    "- **Interpretability**: Each smooth function can be visualized to understand the relationship between a predictor and the response.\n",
    "- **Additivity**: The effect of each predictor is additive, making the model easier to interpret than fully non-linear models.\n",
    "\n",
    "### 3.4 Example: GAM with Synthetic Data\n",
    "\n",
    "Since the wage dataset has path issues, we'll create a synthetic dataset to demonstrate GAMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pygam import LinearGAM, s\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create synthetic data with non-linear relationships\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "# Feature 1: Age (20 to 70)\n",
    "age = np.random.uniform(20, 70, n_samples)\n",
    "\n",
    "# Feature 2: Experience (0 to 40)\n",
    "experience = np.random.uniform(0, 40, n_samples)\n",
    "\n",
    "# Response: Wage with non-linear relationships\n",
    "# Wage increases with age (with diminishing returns) and experience (quadratic)\n",
    "wage = (50 + 2 * np.sqrt(age) + 0.5 * experience - 0.01 * experience**2 + \n",
    "        np.random.normal(0, 5, n_samples))\n",
    "\n",
    "# Combine into a design matrix\n",
    "X = np.column_stack([age, experience])\n",
    "\n",
    "print(\"Synthetic Dataset Created\")\n",
    "print(f\"Number of samples: {n_samples}\")\n",
    "print(f\"Features: Age, Experience\")\n",
    "print(f\"Response: Wage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea79682",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit a GAM with smooth terms for both features\n",
    "gam = LinearGAM(s(0, n_splines=10) + s(1, n_splines=10)).fit(X, wage)\n",
    "\n",
    "# Print the model summary\n",
    "print(gam.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot partial dependence plots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot for Age\n",
    "XX = gam.generate_X_grid(term=0)\n",
    "axs[0].plot(XX[:, 0], gam.partial_dependence(term=0, X=XX))\n",
    "axs[0].plot(XX[:, 0], gam.partial_dependence(term=0, X=XX, width=0.95)[1], c='r', ls='--')\n",
    "axs[0].set_xlabel('Age')\n",
    "axs[0].set_ylabel('Partial Effect on Wage')\n",
    "axs[0].set_title('Partial Dependence: Age')\n",
    "\n",
    "# Plot for Experience\n",
    "XX = gam.generate_X_grid(term=1)\n",
    "axs[1].plot(XX[:, 1], gam.partial_dependence(term=1, X=XX))\n",
    "axs[1].plot(XX[:, 1], gam.partial_dependence(term=1, X=XX, width=0.95)[1], c='r', ls='--')\n",
    "axs[1].set_xlabel('Experience')\n",
    "axs[1].set_ylabel('Partial Effect on Wage')\n",
    "axs[1].set_title('Partial Dependence: Experience')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ffb10",
   "metadata": {},
   "source": [
    "\n",
    "### 3.5 Interpreting GAM Plots\n",
    "\n",
    "The **partial dependence plots** show how each feature affects the response variable while holding other features constant:\n",
    "\n",
    "- The solid line shows the estimated smooth function.\n",
    "- The dashed lines show the confidence intervals.\n",
    "- Non-linear patterns indicate that a simple linear model would not capture the relationship adequately.\n",
    "\n",
    "In our synthetic example:\n",
    "- **Age** shows a non-linear relationship (square root function).\n",
    "- **Experience** shows a quadratic relationship (increases then levels off).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8764aee",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Interaction Terms\n",
    "\n",
    "### 4.1 What are Interaction Terms?\n",
    "\n",
    "Interaction terms account for the combined effect of two or more predictors on the response variable. In other words, an interaction term is used when the effect of one predictor variable on the response variable is **different at different values** of another predictor variable.\n",
    "\n",
    "### 4.2 Mathematical Formulation\n",
    "\n",
    "For two predictors, X₁ and X₂, an interaction term is created by multiplying the two predictors: X₁ × X₂.\n",
    "\n",
    "**Model without interaction:**\n",
    "Y = β₀ + β₁X₁ + β₂X₂ + ε\n",
    "\n",
    "**Model with interaction:**\n",
    "Y = β₀ + β₁X₁ + β₂X₂ + β₃(X₁ × X₂) + ε\n",
    "\n",
    "Here, the coefficient β₃ represents the interaction effect.\n",
    "\n",
    "### 4.3 Interpreting Interaction Terms\n",
    "\n",
    "When an interaction term is present:\n",
    "\n",
    "- **β₁**: The effect of X₁ on Y when X₂ = 0\n",
    "- **β₂**: The effect of X₂ on Y when X₁ = 0\n",
    "- **β₃**: How the effect of X₁ on Y changes for each unit increase in X₂ (and vice versa)\n",
    "\n",
    "### 4.4 Example: Interaction between Literacy and Wealth\n",
    "\n",
    "We'll use the Guerry dataset, which contains data on French departments in the 1830s, to explore the interaction between literacy and wealth on lottery participation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load the dataset\n",
    "df_interaction = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").data\n",
    "\n",
    "print(\"Dataset Preview:\")\n",
    "print(df_interaction[['Lottery', 'Literacy', 'Wealth']].head())\n",
    "print(\"\\nDataset Shape:\", df_interaction.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit a model WITHOUT interaction terms\n",
    "model_no_interaction = smf.ols(formula='Lottery ~ Literacy + Wealth', data=df_interaction).fit()\n",
    "\n",
    "print(\"Model WITHOUT Interaction:\")\n",
    "print(model_no_interaction.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit a model WITH interaction terms\n",
    "# The * operator in the formula automatically includes main effects and interaction\n",
    "interaction_model = smf.ols(formula='Lottery ~ Literacy * Wealth', data=df_interaction).fit()\n",
    "\n",
    "print(\"\\nModel WITH Interaction:\")\n",
    "print(interaction_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9311bed",
   "metadata": {},
   "source": [
    "\n",
    "### 4.5 Comparing Models\n",
    "\n",
    "Compare the two models:\n",
    "\n",
    "1. **R-squared**: Has the model fit improved with the interaction term?\n",
    "2. **Coefficient significance**: Is the interaction term statistically significant?\n",
    "3. **Interpretation**: How does the interaction change our understanding of the relationship?\n",
    "\n",
    "In the Guerry dataset example:\n",
    "- The interaction term `Literacy:Wealth` shows whether the effect of literacy on lottery participation depends on the wealth level of the department.\n",
    "- If the interaction coefficient is significant, it suggests that literacy and wealth have a combined effect beyond their individual contributions.\n",
    "\n",
    "### 4.6 Visualizing Interactions\n",
    "\n",
    "Interaction effects are often easier to understand through visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557892f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a visualization of the interaction effect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a grid of Literacy values\n",
    "literacy_range = np.linspace(df_interaction['Literacy'].min(), \n",
    "                              df_interaction['Literacy'].max(), 100)\n",
    "\n",
    "# Plot for different levels of Wealth (low, medium, high)\n",
    "wealth_levels = [df_interaction['Wealth'].quantile(0.25),\n",
    "                 df_interaction['Wealth'].quantile(0.50),\n",
    "                 df_interaction['Wealth'].quantile(0.75)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for wealth in wealth_levels:\n",
    "    # Predict Lottery for each literacy level at this wealth level\n",
    "    predictions = (interaction_model.params['Intercept'] + \n",
    "                   interaction_model.params['Literacy'] * literacy_range +\n",
    "                   interaction_model.params['Wealth'] * wealth +\n",
    "                   interaction_model.params['Literacy:Wealth'] * literacy_range * wealth)\n",
    "    \n",
    "    plt.plot(literacy_range, predictions, label=f'Wealth = {wealth:.1f}')\n",
    "\n",
    "plt.xlabel('Literacy')\n",
    "plt.ylabel('Predicted Lottery')\n",
    "plt.title('Interaction Effect: Literacy × Wealth on Lottery Participation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db3c0e",
   "metadata": {},
   "source": [
    "\n",
    "The plot shows how the relationship between Literacy and Lottery participation changes at different levels of Wealth. If the lines are parallel, there's no interaction. If they have different slopes, there's an interaction effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952a97a",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Conclusion\n",
    "\n",
    "This notebook provided an overview of advanced linear models, including Generalized Linear Models (GLMs), Generalized Additive Models (GAMs), and interaction terms. These models offer greater flexibility than standard linear models and can be used to model a wider variety of data and relationships.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "**Generalized Linear Models (GLMs)** extend linear regression to handle non-normal response variables by using appropriate probability distributions and link functions. They are particularly useful for count data, binary outcomes, and positive continuous data.\n",
    "\n",
    "**Generalized Additive Models (GAMs)** extend GLMs by allowing non-linear relationships between predictors and the response through the use of smooth functions. They maintain interpretability while capturing complex patterns in the data.\n",
    "\n",
    "**Interaction Terms** allow us to capture the combined effects of multiple predictors, revealing how the effect of one variable depends on the level of another. They are essential for understanding complex relationships in multivariate data.\n",
    "\n",
    "By understanding and utilizing these advanced techniques, you can build more powerful and accurate predictive models that better reflect the complexity of real-world data.\n",
    "\n",
    "### When to Use Each Model\n",
    "\n",
    "| Model | Use When |\n",
    "|-------|----------|\n",
    "| **Linear Regression** | Response is continuous and normally distributed, relationships are linear |\n",
    "| **Logistic Regression** | Response is binary (0/1) |\n",
    "| **GLM (Poisson)** | Response is count data (0, 1, 2, ...) |\n",
    "| **GLM (Gamma)** | Response is positive continuous with constant coefficient of variation |\n",
    "| **GAM** | Relationships are non-linear but you want to maintain interpretability |\n",
    "| **Interaction Terms** | The effect of one variable depends on another variable |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Experiment with different GLM families for various types of data\n",
    "- Try GAMs on datasets with known non-linear relationships\n",
    "- Practice identifying and interpreting interaction effects\n",
    "- Combine these techniques (e.g., GAMs with interaction terms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9b371",
   "metadata": {},
   "source": [
    "\n",
    "## 6. References\n",
    "\n",
    "- [The ultimate beginner's guide to generalized linear models (GLMs)](https://albert-rapp.de/posts/14_glms/14_glms)\n",
    "- [A Comprehensive Guide to Interaction Terms in Linear Regression](https://developer.nvidia.com/blog/a-comprehensive-guide-to-interaction-terms-in-linear-regression/)\n",
    "- [Understanding Generalized Additive Models (GAMs): A Comprehensive Guide](https://www.analyticsvidhya.com/blog/2023/09/understanding-generalized-additive-models-gams-a-comprehensive-guide/)\n",
    "- [statsmodels documentation](https://www.statsmodels.org/stable/index.html)\n",
    "- [pygam documentation](https://pygam.readthedocs.io/en/latest/)\n",
    "- [Penn State STAT 504 - GLMs](https://online.stat.psu.edu/stat504/lesson/6/6.1)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
