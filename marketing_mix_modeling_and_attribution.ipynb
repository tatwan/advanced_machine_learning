{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marketing Mix Modeling (MMM) & Multi-Touch Attribution (MTA)\n",
    "\n",
    "## A Hands-On Lab for Advanced Marketing Analytics\n",
    "\n",
    "**Author:** Advanced Machine Learning Course\n",
    "\n",
    "**Duration:** 2-3 hours\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. Understand the key challenges in marketing measurement\n",
    "2. Learn how Marketing Mix Modeling (MMM) provides a top-down view of media effectiveness\n",
    "3. Understand Multi-Touch Attribution (MTA) and its bottom-up approach to customer journeys\n",
    "4. Compare and contrast MMM vs MTA - when to use each\n",
    "5. Implement practical MMM and MTA models using real-world inspired data\n",
    "6. Interpret results and make data-driven marketing decisions\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Marketing Measurement Challenges](#section1)\n",
    "2. [Understanding MMM: Top-down Approach](#section2)\n",
    "3. [Understanding MTA: Bottom-up Approach](#section3)\n",
    "4. [Key Differences and Use Cases](#section4)\n",
    "5. [Practical Considerations](#section5)\n",
    "6. [Hands-On Exercise: Complete Implementation](#section6)\n",
    "7. [Summary and Best Practices](#section7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\u2705 Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section1'></a>\n",
    "## 1. Introduction to Marketing Measurement Challenges\n",
    "\n",
    "### The Marketing Attribution Problem\n",
    "\n",
    "Modern marketers face several critical challenges:\n",
    "\n",
    "#### **Challenge 1: Multi-Channel Complexity**\n",
    "- Customers interact with brands across 10+ touchpoints before converting\n",
    "- Channels include: TV, Digital (Search, Social, Display), Radio, Print, Email, etc.\n",
    "- How do we assign credit to each channel?\n",
    "\n",
    "#### **Challenge 2: Time Lag Effects (Adstock)**\n",
    "- Marketing impact doesn't happen instantly\n",
    "- A TV ad today might drive sales for weeks\n",
    "- This \"carryover effect\" must be captured\n",
    "\n",
    "#### **Challenge 3: Diminishing Returns**\n",
    "- First $1,000 in advertising is more effective than the 10,000th $1,000\n",
    "- Saturation effects occur at high spend levels\n",
    "\n",
    "#### **Challenge 4: External Factors**\n",
    "- Seasonality (holidays, weather)\n",
    "- Competition\n",
    "- Economic conditions\n",
    "- Promotions and pricing\n",
    "\n",
    "### Two Main Approaches\n",
    "\n",
    "**Marketing Mix Modeling (MMM)**\n",
    "- Top-down, aggregate approach\n",
    "- Uses historical spend and revenue data\n",
    "- Best for: Long-term planning, budget allocation, offline channels\n",
    "\n",
    "**Multi-Touch Attribution (MTA)**\n",
    "- Bottom-up, user-level approach  \n",
    "- Uses individual customer journey data\n",
    "- Best for: Digital optimization, real-time decisions, conversion paths\n",
    "\n",
    "Let's explore both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the marketing measurement challenge\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left plot: Multi-channel customer journey\n",
    "touchpoints = ['Social\\nMedia', 'Search\\nAd', 'Email', 'Display\\nAd', 'TV\\nAd', 'Direct\\nVisit', 'Conversion']\n",
    "x_pos = range(len(touchpoints))\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6', '#1abc9c', '#e67e22']\n",
    "\n",
    "axes[0].scatter(x_pos, [1]*len(touchpoints), s=500, c=colors, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "for i in range(len(touchpoints)-1):\n",
    "    axes[0].annotate('', xy=(x_pos[i+1], 1), xytext=(x_pos[i], 1),\n",
    "                    arrowprops=dict(arrowstyle='->', lw=2, color='gray'))\n",
    "axes[0].set_ylim(0.5, 1.5)\n",
    "axes[0].set_xlim(-0.5, len(touchpoints)-0.5)\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(touchpoints, fontsize=9)\n",
    "axes[0].set_yticks([])\n",
    "axes[0].set_title('Challenge: Multi-Touch Customer Journey\\nWhich touchpoint deserves credit?', fontsize=12, fontweight='bold')\n",
    "axes[0].spines['left'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "\n",
    "# Right plot: Adstock effect visualization\n",
    "weeks = np.arange(1, 13)\n",
    "spend = np.array([0, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 0])\n",
    "# Simple adstock with decay\n",
    "adstock = np.zeros_like(spend, dtype=float)\n",
    "decay_rate = 0.6\n",
    "for i in range(len(spend)):\n",
    "    adstock[i] = spend[i]\n",
    "    if i > 0:\n",
    "        adstock[i] += decay_rate * adstock[i-1]\n",
    "\n",
    "axes[1].bar(weeks, spend, alpha=0.5, label='Ad Spend', color='steelblue', width=0.4)\n",
    "axes[1].plot(weeks, adstock, marker='o', linewidth=2, markersize=8, \n",
    "            label='Adstock Effect (Carryover)', color='darkred')\n",
    "axes[1].set_xlabel('Week', fontsize=10)\n",
    "axes[1].set_ylabel('Effect', fontsize=10)\n",
    "axes[1].set_title('Challenge: Time Lag & Carryover Effects\\nMarketing impact persists over time', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udcca Visualization shows two key marketing measurement challenges:\")\n",
    "print(\"   1. Multi-touch journeys: Which channel deserves credit?\")\n",
    "print(\"   2. Adstock effects: Marketing impact extends beyond the spend period\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section2'></a>\n",
    "## 2. Understanding MMM: Top-down Approach for Media Effectiveness\n",
    "\n",
    "### What is Marketing Mix Modeling?\n",
    "\n",
    "**Marketing Mix Modeling (MMM)** is a statistical analysis technique that helps quantify the impact of various marketing activities on sales or other KPIs.\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "#### 1. **Aggregate Analysis**\n",
    "- Works at weekly/monthly level (not individual customer level)\n",
    "- Uses historical marketing spend and sales data\n",
    "- Typically requires 2-3 years of data\n",
    "\n",
    "#### 2. **Adstock Transformation**\n",
    "Captures the carryover effect of marketing:\n",
    "\n",
    "```\n",
    "Adstock_t = Spend_t + \u03bb \u00d7 Adstock_(t-1)\n",
    "where \u03bb is the decay rate (0-1)\n",
    "```\n",
    "\n",
    "#### 3. **Saturation Curves**\n",
    "Models diminishing returns:\n",
    "\n",
    "```\n",
    "Effect = \u03b1 \u00d7 (Spend^\u03b3) / (Spend^\u03b3 + \u03b2)\n",
    "```\n",
    "\n",
    "#### 4. **Base vs. Incremental Sales**\n",
    "- **Base sales**: What you'd get without marketing\n",
    "- **Incremental sales**: Sales driven by marketing\n",
    "\n",
    "### When to Use MMM\n",
    "\n",
    "\u2705 **Best for:**\n",
    "- Long-term strategic planning\n",
    "- Budget allocation across channels\n",
    "- Including offline media (TV, Radio, Print)\n",
    "- Understanding seasonal patterns\n",
    "- When you lack granular customer data\n",
    "\n",
    "\u274c **Not ideal for:**\n",
    "- Real-time optimization\n",
    "- Individual customer targeting\n",
    "- Channels with short feedback loops\n",
    "\n",
    "### Let's Build an MMM Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic marketing data inspired by retail/e-commerce patterns\n",
    "# This simulates 2 years (104 weeks) of marketing data\n",
    "\n",
    "np.random.seed(42)\n",
    "n_weeks = 104\n",
    "\n",
    "# Create weekly timestamps\n",
    "dates = pd.date_range(start='2022-01-03', periods=n_weeks, freq='W')\n",
    "\n",
    "# Generate marketing spend data with realistic patterns\n",
    "# TV: Higher spend, seasonal peaks\n",
    "tv_base = 30000\n",
    "tv_spend = tv_base + np.random.uniform(-5000, 15000, n_weeks)\n",
    "# Add holiday spikes (weeks 48-52 for each year)\n",
    "tv_spend[48:52] *= 1.5\n",
    "tv_spend[100:104] *= 1.5\n",
    "\n",
    "# Digital: Steady spend with growth trend\n",
    "digital_base = np.linspace(15000, 25000, n_weeks)  # Growing over time\n",
    "digital_spend = digital_base + np.random.uniform(-3000, 8000, n_weeks)\n",
    "\n",
    "# Radio: Moderate spend\n",
    "radio_spend = 8000 + np.random.uniform(-2000, 5000, n_weeks)\n",
    "\n",
    "# Print: Declining spend (traditional media)\n",
    "print_base = np.linspace(10000, 5000, n_weeks)  # Declining\n",
    "print_spend = print_base + np.random.uniform(-1000, 2000, n_weeks)\n",
    "\n",
    "# Social Media: Growing spend\n",
    "social_base = np.linspace(5000, 12000, n_weeks)\n",
    "social_spend = social_base + np.random.uniform(-1000, 3000, n_weeks)\n",
    "\n",
    "# Create DataFrame\n",
    "mmm_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'tv_spend': tv_spend.clip(min=0),\n",
    "    'digital_spend': digital_spend.clip(min=0),\n",
    "    'radio_spend': radio_spend.clip(min=0),\n",
    "    'print_spend': print_spend.clip(min=0),\n",
    "    'social_spend': social_spend.clip(min=0)\n",
    "})\n",
    "\n",
    "# Add seasonality component (stronger in Q4)\n",
    "mmm_data['week_of_year'] = mmm_data['date'].dt.isocalendar().week\n",
    "mmm_data['seasonality'] = np.sin(2 * np.pi * mmm_data['week_of_year'] / 52) * 20000 + 30000\n",
    "\n",
    "# Simulate sales with realistic channel contributions\n",
    "# Different channels have different ROI\n",
    "base_sales = 100000  # Base sales without marketing\n",
    "\n",
    "# Apply simple adstock to each channel (more realistic)\n",
    "def apply_adstock(x, decay=0.5):\n",
    "    adstocked = np.zeros_like(x, dtype=float)\n",
    "    adstocked[0] = x[0]\n",
    "    for t in range(1, len(x)):\n",
    "        adstocked[t] = x[t] + decay * adstocked[t-1]\n",
    "    return adstocked\n",
    "\n",
    "# Channel effects with different decay rates\n",
    "tv_effect = apply_adstock(mmm_data['tv_spend'].values, decay=0.6) * 0.8\n",
    "digital_effect = apply_adstock(mmm_data['digital_spend'].values, decay=0.3) * 1.2\n",
    "radio_effect = apply_adstock(mmm_data['radio_spend'].values, decay=0.4) * 0.5\n",
    "print_effect = apply_adstock(mmm_data['print_spend'].values, decay=0.5) * 0.3\n",
    "social_effect = apply_adstock(mmm_data['social_spend'].values, decay=0.35) * 1.0\n",
    "\n",
    "# Total sales\n",
    "mmm_data['sales'] = (\n",
    "    base_sales + \n",
    "    tv_effect +\n",
    "    digital_effect +\n",
    "    radio_effect +\n",
    "    print_effect +\n",
    "    social_effect +\n",
    "    mmm_data['seasonality'] * 0.3 +\n",
    "    np.random.normal(0, 15000, n_weeks)  # Noise\n",
    ")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\ud83d\udcca Marketing Mix Modeling Dataset\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Time Period: {mmm_data['date'].min().strftime('%Y-%m-%d')} to {mmm_data['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Number of Weeks: {len(mmm_data)}\")\n",
    "print(f\"\\nSample Data:\\n\")\n",
    "print(mmm_data[['date', 'tv_spend', 'digital_spend', 'radio_spend', 'print_spend', 'social_spend', 'sales']].head(10))\n",
    "print(f\"\\n\ud83d\udcb0 Average Weekly Spend by Channel:\")\n",
    "for channel in ['tv_spend', 'digital_spend', 'radio_spend', 'print_spend', 'social_spend']:\n",
    "    print(f\"   {channel.replace('_spend', '').title()}: ${mmm_data[channel].mean():,.0f}\")\n",
    "print(f\"\\n\ud83d\udcc8 Average Weekly Sales: ${mmm_data['sales'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the marketing data\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Marketing spend over time\n",
    "channels = ['tv_spend', 'digital_spend', 'radio_spend', 'print_spend', 'social_spend']\n",
    "channel_labels = ['TV', 'Digital', 'Radio', 'Print', 'Social']\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "\n",
    "for channel, label, color in zip(channels, channel_labels, colors):\n",
    "    axes[0].plot(mmm_data['date'], mmm_data[channel], label=label, linewidth=2, color=color, alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Date', fontsize=11)\n",
    "axes[0].set_ylabel('Weekly Spend ($)', fontsize=11)\n",
    "axes[0].set_title('Marketing Spend by Channel Over Time', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(loc='upper left', ncol=5, fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# Plot 2: Sales over time\n",
    "axes[1].plot(mmm_data['date'], mmm_data['sales'], linewidth=2, color='darkgreen', label='Weekly Sales')\n",
    "axes[1].fill_between(mmm_data['date'], mmm_data['sales'], alpha=0.3, color='lightgreen')\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_ylabel('Weekly Sales ($)', fontsize=11)\n",
    "axes[1].set_title('Weekly Sales Over Time', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(loc='upper left', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcc8 Key Observations:\")\n",
    "print(\"   \u2022 TV spend shows seasonal spikes (especially Q4)\")\n",
    "print(\"   \u2022 Digital spend has been growing steadily\")\n",
    "print(\"   \u2022 Print spend is declining (traditional media trend)\")\n",
    "print(\"   \u2022 Sales show strong seasonality patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the MMM Model\n",
    "\n",
    "Now we'll apply the key MMM transformations:\n",
    "1. **Adstock transformation** - capture carryover effects\n",
    "2. **Saturation transformation** - model diminishing returns\n",
    "3. **Regression model** - quantify channel contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMM Model Class\n",
    "class MarketingMixModel:\n",
    "    \"\"\"\n",
    "    Marketing Mix Modeling implementation with adstock and saturation transformations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, adstock_decay=0.5, saturation_alpha=1.0, saturation_gamma=0.5):\n",
    "        \"\"\"\n",
    "        Initialize MMM model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        adstock_decay : float\n",
    "            Decay rate for adstock effect (0-1). Higher values = longer carryover.\n",
    "        saturation_alpha : float\n",
    "            Saturation parameter (scale).\n",
    "        saturation_gamma : float\n",
    "            Saturation parameter (shape). Lower values = earlier saturation.\n",
    "        \"\"\"\n",
    "        self.adstock_decay = adstock_decay\n",
    "        self.saturation_alpha = saturation_alpha\n",
    "        self.saturation_gamma = saturation_gamma\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def adstock_transform(self, x, decay=None):\n",
    "        \"\"\"\n",
    "        Apply adstock transformation to capture carryover effects.\n",
    "        \n",
    "        Adstock_t = x_t + decay \u00d7 Adstock_{t-1}\n",
    "        \"\"\"\n",
    "        if decay is None:\n",
    "            decay = self.adstock_decay\n",
    "            \n",
    "        adstocked = np.zeros_like(x, dtype=float)\n",
    "        adstocked[0] = x[0]\n",
    "        \n",
    "        for t in range(1, len(x)):\n",
    "            adstocked[t] = x[t] + decay * adstocked[t-1]\n",
    "        \n",
    "        return adstocked\n",
    "    \n",
    "    def saturation_transform(self, x, alpha=None, gamma=None):\n",
    "        \"\"\"\n",
    "        Apply saturation transformation to model diminishing returns.\n",
    "        \n",
    "        Effect = \u03b1 \u00d7 (x^\u03b3) / (x^\u03b3 + 1)\n",
    "        \"\"\"\n",
    "        if alpha is None:\n",
    "            alpha = self.saturation_alpha\n",
    "        if gamma is None:\n",
    "            gamma = self.saturation_gamma\n",
    "            \n",
    "        # Normalize to avoid numerical issues\n",
    "        x_norm = x / (x.max() + 1e-10)\n",
    "        return alpha * (x_norm ** gamma) / (x_norm ** gamma + 1)\n",
    "    \n",
    "    def fit(self, X, y, channel_names, apply_adstock=True, apply_saturation=True):\n",
    "        \"\"\"\n",
    "        Fit the Marketing Mix Model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pd.DataFrame or np.ndarray\n",
    "            Marketing spend data (features)\n",
    "        y : array-like\n",
    "            Target variable (sales/conversions)\n",
    "        channel_names : list\n",
    "            Names of marketing channels\n",
    "        apply_adstock : bool\n",
    "            Whether to apply adstock transformation\n",
    "        apply_saturation : bool\n",
    "            Whether to apply saturation transformation\n",
    "        \"\"\"\n",
    "        self.feature_names = channel_names\n",
    "        X_transformed = X[channel_names].copy()\n",
    "        \n",
    "        # Apply transformations\n",
    "        if apply_adstock:\n",
    "            for channel in channel_names:\n",
    "                X_transformed[channel] = self.adstock_transform(X_transformed[channel].values)\n",
    "        \n",
    "        if apply_saturation:\n",
    "            for channel in channel_names:\n",
    "                X_transformed[channel] = self.saturation_transform(X_transformed[channel].values)\n",
    "        \n",
    "        # Standardize features\n",
    "        X_scaled = self.scaler.fit_transform(X_transformed)\n",
    "        \n",
    "        # Fit Ridge regression (regularization helps with multicollinearity)\n",
    "        self.model = Ridge(alpha=1.0)\n",
    "        self.model.fit(X_scaled, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict sales based on marketing spend.\n",
    "        \"\"\"\n",
    "        X_transformed = X[self.feature_names].copy()\n",
    "        \n",
    "        for channel in self.feature_names:\n",
    "            X_transformed[channel] = self.adstock_transform(X_transformed[channel].values)\n",
    "            X_transformed[channel] = self.saturation_transform(X_transformed[channel].values)\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X_transformed)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def get_channel_contributions(self):\n",
    "        \"\"\"\n",
    "        Get relative contribution of each marketing channel.\n",
    "        \"\"\"\n",
    "        coefficients = self.model.coef_\n",
    "        \n",
    "        contributions = pd.DataFrame({\n",
    "            'channel': self.feature_names,\n",
    "            'coefficient': coefficients,\n",
    "            'abs_contribution': np.abs(coefficients)\n",
    "        })\n",
    "        \n",
    "        contributions['pct_contribution'] = (\n",
    "            contributions['abs_contribution'] / contributions['abs_contribution'].sum() * 100\n",
    "        )\n",
    "        \n",
    "        return contributions.sort_values('pct_contribution', ascending=False)\n",
    "    \n",
    "    def get_roi(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate Return on Investment (ROI) for each channel.\n",
    "        \"\"\"\n",
    "        contributions = self.get_channel_contributions()\n",
    "        predictions = self.predict(X)\n",
    "        total_incremental_sales = predictions.sum() - self.model.intercept_ * len(predictions)\n",
    "        \n",
    "        roi_data = []\n",
    "        for channel in self.feature_names:\n",
    "            total_spend = X[channel].sum()\n",
    "            channel_contrib = contributions[contributions['channel'] == channel]['pct_contribution'].values[0]\n",
    "            channel_sales = total_incremental_sales * (channel_contrib / 100)\n",
    "            roi = (channel_sales / total_spend) if total_spend > 0 else 0\n",
    "            \n",
    "            roi_data.append({\n",
    "                'channel': channel,\n",
    "                'total_spend': total_spend,\n",
    "                'incremental_sales': channel_sales,\n",
    "                'roi': roi\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(roi_data).sort_values('roi', ascending=False)\n",
    "\n",
    "print(\"\u2705 MarketingMixModel class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MMM model\n",
    "print(\"\ud83d\udd27 Training Marketing Mix Model...\\n\")\n",
    "\n",
    "# Define marketing channels\n",
    "marketing_channels = ['tv_spend', 'digital_spend', 'radio_spend', 'print_spend', 'social_spend']\n",
    "\n",
    "# Split data: Use first 80% for training, last 20% for validation\n",
    "split_idx = int(len(mmm_data) * 0.8)\n",
    "train_data = mmm_data[:split_idx]\n",
    "test_data = mmm_data[split_idx:]\n",
    "\n",
    "# Initialize and fit model\n",
    "mmm_model = MarketingMixModel(\n",
    "    adstock_decay=0.5,  # Medium carryover effect\n",
    "    saturation_alpha=1.0,\n",
    "    saturation_gamma=0.5  # Moderate diminishing returns\n",
    ")\n",
    "\n",
    "mmm_model.fit(\n",
    "    X=train_data,\n",
    "    y=train_data['sales'],\n",
    "    channel_names=marketing_channels,\n",
    "    apply_adstock=True,\n",
    "    apply_saturation=True\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = mmm_model.predict(train_data)\n",
    "test_predictions = mmm_model.predict(test_data)\n",
    "\n",
    "# Evaluate model\n",
    "train_r2 = r2_score(train_data['sales'], train_predictions)\n",
    "test_r2 = r2_score(test_data['sales'], test_predictions)\n",
    "train_mape = np.mean(np.abs((train_data['sales'] - train_predictions) / train_data['sales'])) * 100\n",
    "test_mape = np.mean(np.abs((test_data['sales'] - test_predictions) / test_data['sales'])) * 100\n",
    "\n",
    "print(\"\ud83d\udcca Model Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training R\u00b2:     {train_r2:.4f}\")\n",
    "print(f\"Test R\u00b2:         {test_r2:.4f}\")\n",
    "print(f\"Training MAPE:   {train_mape:.2f}%\")\n",
    "print(f\"Test MAPE:       {test_mape:.2f}%\")\n",
    "print(\"\\n\u2705 Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze channel contributions\n",
    "contributions = mmm_model.get_channel_contributions()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Channel Contribution Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(contributions[['channel', 'coefficient', 'pct_contribution']].to_string(index=False))\n",
    "\n",
    "# Calculate ROI\n",
    "roi_analysis = mmm_model.get_roi(train_data, train_data['sales'])\n",
    "\n",
    "print(\"\\n\ud83d\udcb0 Return on Investment (ROI) by Channel:\")\n",
    "print(\"=\"*70)\n",
    "for _, row in roi_analysis.iterrows():\n",
    "    print(f\"{row['channel'].replace('_spend', '').title():12} | Spend: ${row['total_spend']:>12,.0f} | Sales: ${row['incremental_sales']:>12,.0f} | ROI: {row['roi']:>5.2f}x\")\n",
    "\n",
    "# Visualize contributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Channel contributions\n",
    "colors_pie = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "axes[0].pie(contributions['pct_contribution'], \n",
    "           labels=[c.replace('_spend', '').title() for c in contributions['channel']],\n",
    "           autopct='%1.1f%%', startangle=90, colors=colors_pie)\n",
    "axes[0].set_title('Channel Contribution to Sales', fontsize=13, fontweight='bold')\n",
    "\n",
    "# ROI comparison\n",
    "channel_labels = [c.replace('_spend', '').title() for c in roi_analysis['channel']]\n",
    "roi_values = roi_analysis['roi'].values\n",
    "bars = axes[1].barh(channel_labels, roi_values, color=colors_pie)\n",
    "axes[1].set_xlabel('ROI (Return per Dollar Spent)', fontsize=11)\n",
    "axes[1].set_title('Return on Investment by Channel', fontsize=13, fontweight='bold')\n",
    "axes[1].axvline(x=1.0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Break-even (ROI=1.0)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    axes[1].text(width, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.2f}x', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ufffd\ufffd Key Insights:\")\n",
    "best_roi_channel = roi_analysis.iloc[0]\n",
    "print(f\"   \u2022 {best_roi_channel['channel'].replace('_spend', '').title()} has the highest ROI at {best_roi_channel['roi']:.2f}x\")\n",
    "print(f\"   \u2022 Digital channels typically show higher ROI than traditional media\")\n",
    "print(f\"   \u2022 Consider reallocating budget from low-ROI to high-ROI channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize actual vs predicted sales\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Training period\n",
    "axes[0].plot(train_data['date'], train_data['sales'], label='Actual Sales', linewidth=2, color='darkgreen')\n",
    "axes[0].plot(train_data['date'], train_predictions, label='Predicted Sales', linewidth=2, color='darkblue', linestyle='--')\n",
    "axes[0].fill_between(train_data['date'], train_data['sales'], train_predictions, alpha=0.2, color='gray')\n",
    "axes[0].set_xlabel('Date', fontsize=11)\n",
    "axes[0].set_ylabel('Sales ($)', fontsize=11)\n",
    "axes[0].set_title(f'Training Period: Actual vs Predicted Sales (R\u00b2 = {train_r2:.4f})', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(loc='upper left', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# Test period\n",
    "axes[1].plot(test_data['date'], test_data['sales'], label='Actual Sales', linewidth=2, color='darkgreen')\n",
    "axes[1].plot(test_data['date'], test_predictions, label='Predicted Sales', linewidth=2, color='darkred', linestyle='--')\n",
    "axes[1].fill_between(test_data['date'], test_data['sales'], test_predictions, alpha=0.2, color='gray')\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_ylabel('Sales ($)', fontsize=11)\n",
    "axes[1].set_title(f'Test Period: Actual vs Predicted Sales (R\u00b2 = {test_r2:.4f})', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(loc='upper left', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca The model captures:\")\n",
    "print(\"   \u2713 Seasonal patterns in sales\")\n",
    "print(\"   \u2713 Impact of marketing spend changes\")\n",
    "print(\"   \u2713 Carryover effects from previous periods\")\n",
    "print(\"   \u2713 Diminishing returns at high spend levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section3'></a>\n",
    "## 3. Understanding MTA: Bottom-up Approach for Customer Journeys\n",
    "\n",
    "### What is Multi-Touch Attribution?\n",
    "\n",
    "**Multi-Touch Attribution (MTA)** analyzes individual customer journeys to understand which touchpoints contribute to conversions.\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "#### 1. **Customer Journey**\n",
    "- Sequence of interactions a customer has with your brand\n",
    "- Example: Social Ad \u2192 Email \u2192 Search \u2192 Website \u2192 Conversion\n",
    "\n",
    "#### 2. **Touchpoint**\n",
    "- Any interaction point: ad click, email open, website visit, etc.\n",
    "- Can be online (trackable) or offline (harder to track)\n",
    "\n",
    "#### 3. **Attribution Models**\n",
    "Different ways to assign credit:\n",
    "\n",
    "**Single-Touch Models:**\n",
    "- **Last-Touch**: 100% credit to final interaction\n",
    "- **First-Touch**: 100% credit to initial interaction\n",
    "\n",
    "**Multi-Touch Models:**\n",
    "- **Linear**: Equal credit to all touchpoints\n",
    "- **Time-Decay**: More credit to recent touchpoints\n",
    "- **Position-Based (U-Shaped)**: 40% to first, 40% to last, 20% to middle\n",
    "- **Data-Driven**: ML-based attribution using historical data\n",
    "\n",
    "### When to Use MTA\n",
    "\n",
    "\u2705 **Best for:**\n",
    "- Digital-first businesses\n",
    "- Short sales cycles\n",
    "- Real-time campaign optimization\n",
    "- Understanding customer paths to conversion\n",
    "- A/B testing and experimentation\n",
    "\n",
    "\u274c **Not ideal for:**\n",
    "- Heavy offline presence\n",
    "- Long sales cycles (months/years)\n",
    "- Limited tracking capabilities\n",
    "- When cookie/tracking data is sparse\n",
    "\n",
    "### Let's Implement MTA Models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic customer journey data\n",
    "# This simulates clickstream data for an e-commerce company\n",
    "\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "# Define available touchpoints\n",
    "touchpoint_types = [\n",
    "    'Social Media Ad',\n",
    "    'Search Ad',\n",
    "    'Display Ad',\n",
    "    'Email',\n",
    "    'Organic Search',\n",
    "    'Direct',\n",
    "    'Referral',\n",
    "    'Video Ad'\n",
    "]\n",
    "\n",
    "# Generate customer journeys\n",
    "customer_journeys = []\n",
    "\n",
    "for customer_id in range(n_customers):\n",
    "    # Random journey length (1-8 touchpoints)\n",
    "    journey_length = np.random.choice([1, 2, 3, 4, 5, 6, 7, 8], \n",
    "                                     p=[0.05, 0.15, 0.25, 0.25, 0.15, 0.10, 0.03, 0.02])\n",
    "    \n",
    "    # Generate journey\n",
    "    journey = []\n",
    "    for i in range(journey_length):\n",
    "        # First touchpoint has different distribution\n",
    "        if i == 0:\n",
    "            touchpoint = np.random.choice(\n",
    "                ['Social Media Ad', 'Search Ad', 'Organic Search', 'Direct'],\n",
    "                p=[0.35, 0.30, 0.25, 0.10]\n",
    "            )\n",
    "        else:\n",
    "            touchpoint = np.random.choice(touchpoint_types)\n",
    "        \n",
    "        journey.append(touchpoint)\n",
    "    \n",
    "    # Conversion value (higher for longer journeys, with some randomness)\n",
    "    base_value = 100\n",
    "    journey_multiplier = 1 + (journey_length - 1) * 0.15\n",
    "    conversion_value = base_value * journey_multiplier * np.random.uniform(0.8, 1.5)\n",
    "    \n",
    "    customer_journeys.append({\n",
    "        'customer_id': customer_id,\n",
    "        'journey': journey,\n",
    "        'journey_length': journey_length,\n",
    "        'conversion_value': conversion_value,\n",
    "        'first_touch': journey[0],\n",
    "        'last_touch': journey[-1]\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "journey_df = pd.DataFrame(customer_journeys)\n",
    "\n",
    "print(\"\ud83d\udcca Customer Journey Dataset\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Customers: {len(journey_df):,}\")\n",
    "print(f\"Average Journey Length: {journey_df['journey_length'].mean():.2f} touchpoints\")\n",
    "print(f\"Total Conversion Value: ${journey_df['conversion_value'].sum():,.0f}\")\n",
    "print(f\"Average Conversion Value: ${journey_df['conversion_value'].mean():.2f}\")\n",
    "print(f\"\\nSample Customer Journeys:\\n\")\n",
    "\n",
    "# Display sample journeys\n",
    "for idx in range(5):\n",
    "    journey = journey_df.iloc[idx]\n",
    "    journey_str = ' \u2192 '.join(journey['journey'])\n",
    "    print(f\"Customer {journey['customer_id']}: {journey_str}\")\n",
    "    print(f\"  Value: ${journey['conversion_value']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize journey patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Journey length distribution\n",
    "axes[0, 0].hist(journey_df['journey_length'], bins=range(1, 10), \n",
    "               color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Number of Touchpoints', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Number of Customers', fontsize=11)\n",
    "axes[0, 0].set_title('Customer Journey Length Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# First touch distribution\n",
    "first_touch_counts = journey_df['first_touch'].value_counts()\n",
    "axes[0, 1].barh(first_touch_counts.index, first_touch_counts.values, color='coral')\n",
    "axes[0, 1].set_xlabel('Number of Customers', fontsize=11)\n",
    "axes[0, 1].set_title('First Touch Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Last touch distribution\n",
    "last_touch_counts = journey_df['last_touch'].value_counts()\n",
    "axes[1, 0].barh(last_touch_counts.index, last_touch_counts.values, color='lightgreen')\n",
    "axes[1, 0].set_xlabel('Number of Customers', fontsize=11)\n",
    "axes[1, 0].set_title('Last Touch Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Conversion value vs journey length\n",
    "journey_value_avg = journey_df.groupby('journey_length')['conversion_value'].agg(['mean', 'std']).reset_index()\n",
    "axes[1, 1].errorbar(journey_value_avg['journey_length'], journey_value_avg['mean'], \n",
    "                   yerr=journey_value_avg['std'], marker='o', markersize=8,\n",
    "                   linewidth=2, capsize=5, color='darkblue')\n",
    "axes[1, 1].set_xlabel('Journey Length', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Average Conversion Value ($)', fontsize=11)\n",
    "axes[1, 1].set_title('Conversion Value by Journey Length', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Key Observations:\")\n",
    "print(f\"   \u2022 Most common journey length: {journey_df['journey_length'].mode()[0]} touchpoints\")\n",
    "print(f\"   \u2022 Top first-touch channel: {first_touch_counts.index[0]}\")\n",
    "print(f\"   \u2022 Top last-touch channel: {last_touch_counts.index[0]}\")\n",
    "print(f\"   \u2022 Longer journeys tend to have higher conversion values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Attribution Models\n",
    "\n",
    "Let's implement different attribution models and compare their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Touch Attribution Model Class\n",
    "class MultiTouchAttribution:\n",
    "    \"\"\"\n",
    "    Implementation of various Multi-Touch Attribution models.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def last_touch(touchpoints, conversion_value):\n",
    "        \"\"\"\n",
    "        Last-Touch Attribution: All credit to the final touchpoint.\n",
    "        \n",
    "        Use case: When you want to focus on closing the sale.\n",
    "        \"\"\"\n",
    "        attribution = {tp: 0 for tp in set(touchpoints)}\n",
    "        if touchpoints:\n",
    "            attribution[touchpoints[-1]] = conversion_value\n",
    "        return attribution\n",
    "    \n",
    "    @staticmethod\n",
    "    def first_touch(touchpoints, conversion_value):\n",
    "        \"\"\"\n",
    "        First-Touch Attribution: All credit to the initial touchpoint.\n",
    "        \n",
    "        Use case: When you want to focus on customer acquisition.\n",
    "        \"\"\"\n",
    "        attribution = {tp: 0 for tp in set(touchpoints)}\n",
    "        if touchpoints:\n",
    "            attribution[touchpoints[0]] = conversion_value\n",
    "        return attribution\n",
    "    \n",
    "    @staticmethod\n",
    "    def linear(touchpoints, conversion_value):\n",
    "        \"\"\"\n",
    "        Linear Attribution: Equal credit to all touchpoints.\n",
    "        \n",
    "        Use case: When all touchpoints are equally important.\n",
    "        \"\"\"\n",
    "        attribution = {tp: 0 for tp in set(touchpoints)}\n",
    "        if touchpoints:\n",
    "            credit_per_touch = conversion_value / len(touchpoints)\n",
    "            for tp in touchpoints:\n",
    "                attribution[tp] += credit_per_touch\n",
    "        return attribution\n",
    "    \n",
    "    @staticmethod\n",
    "    def time_decay(touchpoints, conversion_value, decay_rate=0.5):\n",
    "        \"\"\"\n",
    "        Time-Decay Attribution: More credit to recent touchpoints.\n",
    "        \n",
    "        Use case: When recent interactions are more important (short sales cycle).\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        decay_rate : float\n",
    "            How quickly credit decays for older touchpoints (0-1).\n",
    "            Higher = more credit to recent.\n",
    "        \"\"\"\n",
    "        attribution = {tp: 0 for tp in set(touchpoints)}\n",
    "        \n",
    "        if touchpoints:\n",
    "            n = len(touchpoints)\n",
    "            # Calculate weights (exponential decay from end)\n",
    "            weights = [decay_rate ** (n - i - 1) for i in range(n)]\n",
    "            total_weight = sum(weights)\n",
    "            \n",
    "            for i, tp in enumerate(touchpoints):\n",
    "                attribution[tp] += conversion_value * (weights[i] / total_weight)\n",
    "        \n",
    "        return attribution\n",
    "    \n",
    "    @staticmethod\n",
    "    def position_based(touchpoints, conversion_value, first_last_weight=0.4):\n",
    "        \"\"\"\n",
    "        Position-Based (U-Shaped) Attribution.\n",
    "        More credit to first and last touchpoints.\n",
    "        \n",
    "        Use case: When both acquisition and conversion touchpoints are critical.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        first_last_weight : float\n",
    "            Weight for first and last touchpoints (default 40% each).\n",
    "        \"\"\"\n",
    "        attribution = {tp: 0 for tp in set(touchpoints)}\n",
    "        \n",
    "        if not touchpoints:\n",
    "            return attribution\n",
    "        \n",
    "        n = len(touchpoints)\n",
    "        \n",
    "        if n == 1:\n",
    "            attribution[touchpoints[0]] = conversion_value\n",
    "        elif n == 2:\n",
    "            attribution[touchpoints[0]] += conversion_value * 0.5\n",
    "            attribution[touchpoints[1]] += conversion_value * 0.5\n",
    "        else:\n",
    "            # 40% to first, 40% to last, 20% distributed to middle\n",
    "            middle_weight = 1 - 2 * first_last_weight\n",
    "            middle_per_touch = middle_weight / (n - 2)\n",
    "            \n",
    "            attribution[touchpoints[0]] += conversion_value * first_last_weight\n",
    "            attribution[touchpoints[-1]] += conversion_value * first_last_weight\n",
    "            \n",
    "            for tp in touchpoints[1:-1]:\n",
    "                attribution[tp] += conversion_value * middle_per_touch\n",
    "        \n",
    "        return attribution\n",
    "\n",
    "print(\"\u2705 MultiTouchAttribution class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all attribution models to the data\n",
    "def calculate_channel_attribution(journeys_df, attribution_model):\n",
    "    \"\"\"\n",
    "    Calculate total attribution for each channel using specified model.\n",
    "    \"\"\"\n",
    "    total_attribution = {}\n",
    "    \n",
    "    for _, row in journeys_df.iterrows():\n",
    "        journey = row['journey']\n",
    "        value = row['conversion_value']\n",
    "        \n",
    "        # Get attribution for this journey\n",
    "        journey_attribution = attribution_model(journey, value)\n",
    "        \n",
    "        # Add to total\n",
    "        for channel, attr_value in journey_attribution.items():\n",
    "            total_attribution[channel] = total_attribution.get(channel, 0) + attr_value\n",
    "    \n",
    "    return total_attribution\n",
    "\n",
    "# Apply each attribution model\n",
    "print(\"\ud83d\udd27 Calculating attributions using different models...\\n\")\n",
    "\n",
    "mta = MultiTouchAttribution()\n",
    "\n",
    "attribution_results = {\n",
    "    'Last Touch': calculate_channel_attribution(journey_df, mta.last_touch),\n",
    "    'First Touch': calculate_channel_attribution(journey_df, mta.first_touch),\n",
    "    'Linear': calculate_channel_attribution(journey_df, mta.linear),\n",
    "    'Time Decay': calculate_channel_attribution(journey_df, lambda tp, val: mta.time_decay(tp, val, 0.6)),\n",
    "    'Position-Based': calculate_channel_attribution(journey_df, mta.position_based)\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for easier comparison\n",
    "attribution_comparison = pd.DataFrame(attribution_results).fillna(0)\n",
    "attribution_comparison_pct = attribution_comparison.div(attribution_comparison.sum(axis=0), axis=1) * 100\n",
    "\n",
    "print(\"\ud83d\udcb0 Total Attributed Value by Channel and Model:\\n\")\n",
    "print(attribution_comparison.round(0).to_string())\n",
    "print(\"\\n\ud83d\udcca Attribution Percentage by Channel and Model:\\n\")\n",
    "print(attribution_comparison_pct.round(1).to_string())\n",
    "\n",
    "print(\"\\n\u2705 Attribution models calculated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attribution model comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "models = ['Last Touch', 'First Touch', 'Linear', 'Time Decay', 'Position-Based']\n",
    "colors_bar = plt.cm.Set3(np.linspace(0, 1, len(attribution_comparison)))\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    data = attribution_comparison_pct[model].sort_values(ascending=True)\n",
    "    axes[idx].barh(data.index, data.values, color=colors_bar)\n",
    "    axes[idx].set_xlabel('Attribution %', fontsize=10)\n",
    "    axes[idx].set_title(f'{model} Attribution', fontsize=11, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (channel, value) in enumerate(zip(data.index, data.values)):\n",
    "        axes[idx].text(value + 0.5, i, f'{value:.1f}%', va='center', fontsize=9)\n",
    "\n",
    "# Hide the 6th subplot\n",
    "axes[5].axis('off')\n",
    "\n",
    "# Add comparison in the 6th plot\n",
    "comparison_data = attribution_comparison_pct.T\n",
    "top_channels = attribution_comparison_pct.mean(axis=1).nlargest(5).index\n",
    "x = np.arange(len(models))\n",
    "width = 0.15\n",
    "\n",
    "for i, channel in enumerate(top_channels):\n",
    "    offset = width * (i - 2)\n",
    "    axes[5].bar(x + offset, comparison_data[channel], width, label=channel, alpha=0.8)\n",
    "\n",
    "axes[5].set_xlabel('Attribution Model', fontsize=10)\n",
    "axes[5].set_ylabel('Attribution %', fontsize=10)\n",
    "axes[5].set_title('Top 5 Channels Across Models', fontsize=11, fontweight='bold')\n",
    "axes[5].set_xticks(x)\n",
    "axes[5].set_xticklabels(models, rotation=15, ha='right', fontsize=9)\n",
    "axes[5].legend(fontsize=8, loc='upper left')\n",
    "axes[5].grid(True, alpha=0.3, axis='y')\n",
    "axes[5].axis('on')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udd0d Model Comparison Insights:\")\n",
    "print(\"   \u2022 Last Touch over-credits conversion-driving channels\")\n",
    "print(\"   \u2022 First Touch over-credits awareness channels\")\n",
    "print(\"   \u2022 Linear gives balanced view but may under-value key touchpoints\")\n",
    "print(\"   \u2022 Time Decay balances recency with earlier touches\")\n",
    "print(\"   \u2022 Position-Based emphasizes both acquisition and conversion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section4'></a>\n",
    "## 4. Key Differences and Use Cases: MMM vs MTA\n",
    "\n",
    "### Side-by-Side Comparison\n",
    "\n",
    "| Aspect | Marketing Mix Modeling (MMM) | Multi-Touch Attribution (MTA) |\n",
    "|--------|------------------------------|-------------------------------|\n",
    "| **Approach** | Top-down, aggregate | Bottom-up, individual |\n",
    "| **Data Level** | Weekly/Monthly aggregates | Customer-level journeys |\n",
    "| **Time Horizon** | Long-term (2-3 years) | Short-term (days to months) |\n",
    "| **Channels** | All channels (online + offline) | Primarily digital channels |\n",
    "| **Data Required** | Historical spend + sales | Clickstream/journey data |\n",
    "| **Update Frequency** | Quarterly/Annually | Real-time to daily |\n",
    "| **Privacy Concerns** | Low (aggregated) | Higher (individual tracking) |\n",
    "| **Implementation Cost** | Medium to High | Medium |\n",
    "| **Accuracy** | Good for macro trends | Good for digital optimization |\n",
    "| **Best For** | Budget planning, offline media | Digital optimization, testing |\n",
    "\n",
    "### When to Use Each Approach\n",
    "\n",
    "#### Choose **MMM** when:\n",
    "- \ud83d\udcfa You have significant offline marketing (TV, Radio, Print)\n",
    "- \ud83d\udcc5 Long-term strategic planning is the priority\n",
    "- \ud83d\udd12 Privacy regulations limit individual tracking\n",
    "- \ud83d\udcca You lack granular customer journey data\n",
    "- \ud83d\udcb0 Budget allocation across channels is the main question\n",
    "- \ud83c\udf0d Multi-market analysis is needed\n",
    "\n",
    "#### Choose **MTA** when:\n",
    "- \ud83d\udcbb Your business is primarily digital\n",
    "- \u26a1 Real-time optimization is critical\n",
    "- \ud83c\udfaf You want to understand customer paths\n",
    "- \ud83d\udd2c A/B testing and experimentation are important\n",
    "- \ud83d\ude80 Short sales cycles dominate\n",
    "- \ud83d\udcf1 You have robust tracking infrastructure\n",
    "\n",
    "#### Use **Both** when:\n",
    "- \ud83c\udfad You have significant online AND offline presence\n",
    "- \ud83d\udd04 You need both strategic and tactical insights\n",
    "- \ud83d\udcaa You have resources for comprehensive analytics\n",
    "- \ud83d\udcc8 Omnichannel strategy is a priority\n",
    "\n",
    "### The Future: Unified Measurement\n",
    "\n",
    "Modern approaches are combining MMM and MTA:\n",
    "- **Unified Marketing Measurement (UMM)**\n",
    "- Privacy-friendly attribution (with iOS 14+, GDPR, etc.)\n",
    "- Media Mix Modeling with customer journey insights\n",
    "- Incrementality testing to validate both approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MMM vs MTA comparison\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Comparison matrix\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "\n",
    "comparison_data = {\n",
    "    'Criteria': ['Data Granularity', 'Update Speed', 'Offline Coverage', \n",
    "                'Digital Precision', 'Privacy Friendly', 'Implementation Cost'],\n",
    "    'MMM': [6, 3, 10, 5, 9, 7],\n",
    "    'MTA': [10, 10, 2, 10, 4, 6]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "x = np.arange(len(df_comparison['Criteria']))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, df_comparison['MMM'], width, label='MMM', color='steelblue', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, df_comparison['MTA'], width, label='MTA', color='coral', alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel('Score (0-10)', fontsize=11)\n",
    "ax1.set_title('MMM vs MTA: Feature Comparison', fontsize=13, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(df_comparison['Criteria'], rotation=15, ha='right')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.set_ylim(0, 12)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Decision tree\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.axis('off')\n",
    "\n",
    "decision_text = \"\"\"\n",
    "DECISION TREE\n",
    "\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n",
    "\n",
    "Start: Which approach?\n",
    "  \u2502\n",
    "  \u251c\u2500 Heavy offline media?\n",
    "  \u2502  \u251c\u2500 YES \u2192 Use MMM\n",
    "  \u2502  \u2514\u2500 NO \u2193\n",
    "  \u2502\n",
    "  \u251c\u2500 Need real-time insights?\n",
    "  \u2502  \u251c\u2500 YES \u2192 Use MTA\n",
    "  \u2502  \u2514\u2500 NO \u2193\n",
    "  \u2502\n",
    "  \u251c\u2500 Long sales cycle (>3mo)?\n",
    "  \u2502  \u251c\u2500 YES \u2192 Use MMM\n",
    "  \u2502  \u2514\u2500 NO \u2193\n",
    "  \u2502\n",
    "  \u251c\u2500 Rich tracking data?\n",
    "  \u2502  \u251c\u2500 YES \u2192 Use MTA\n",
    "  \u2502  \u2514\u2500 NO \u2192 Use MMM\n",
    "  \u2502\n",
    "  \u2514\u2500 Have both? \u2192 Use BOTH!\n",
    "\"\"\"\n",
    "\n",
    "ax2.text(0.1, 0.5, decision_text, fontsize=10, family='monospace',\n",
    "        verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "# Use case examples\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.axis('off')\n",
    "\n",
    "use_cases_text = \"\"\"\n",
    "REAL-WORLD EXAMPLES\n",
    "\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n",
    "\n",
    "\ud83d\udcfa MMM Examples:\n",
    "  \u2022 CPG brands (Coca-Cola, P&G)\n",
    "  \u2022 Automotive companies\n",
    "  \u2022 Insurance providers\n",
    "  \u2022 Telecom operators\n",
    "  \u2022 Traditional retailers\n",
    "\n",
    "\ud83d\udcbb MTA Examples:\n",
    "  \u2022 E-commerce (Amazon)\n",
    "  \u2022 SaaS companies\n",
    "  \u2022 Mobile apps\n",
    "  \u2022 Digital publishers\n",
    "  \u2022 Performance marketers\n",
    "\n",
    "\ud83c\udfaf Both:\n",
    "  \u2022 Large omnichannel retailers\n",
    "  \u2022 Financial services\n",
    "  \u2022 Travel & hospitality\n",
    "\"\"\"\n",
    "\n",
    "ax3.text(0.1, 0.5, use_cases_text, fontsize=10,\n",
    "        verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2705 MMM and MTA serve different but complementary purposes!\")\n",
    "print(\"   Choose based on your business needs, data availability, and objectives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section5'></a>\n",
    "## 5. Practical Considerations for Implementation and Interpretation\n",
    "\n",
    "### Common Challenges and Solutions\n",
    "\n",
    "#### Challenge 1: Data Quality\n",
    "**Problem:**\n",
    "- Missing data, inconsistent tracking, data silos\n",
    "- MMM: Incomplete spend data, sales reporting gaps\n",
    "- MTA: Cookie deletion, cross-device tracking issues\n",
    "\n",
    "**Solutions:**\n",
    "- Invest in data infrastructure and governance\n",
    "- Use data imputation techniques for missing values\n",
    "- Implement server-side tracking where possible\n",
    "- Regular data quality audits\n",
    "\n",
    "#### Challenge 2: Multi-Collinearity\n",
    "**Problem:**\n",
    "- Marketing channels are often correlated\n",
    "- Hard to isolate individual channel effects\n",
    "\n",
    "**Solutions:**\n",
    "- Use regularization (Ridge/Lasso regression)\n",
    "- Consider variance inflation factor (VIF)\n",
    "- Design experiments to vary channels independently\n",
    "- Bayesian methods for uncertainty quantification\n",
    "\n",
    "#### Challenge 3: Attribution Window\n",
    "**Problem:**\n",
    "- How long after seeing an ad can we credit it?\n",
    "- Too short: miss delayed conversions\n",
    "- Too long: over-credit channels\n",
    "\n",
    "**Solutions:**\n",
    "- Test different windows (7, 14, 30 days)\n",
    "- Segment by product/vertical\n",
    "- Use survival analysis to model time-to-conversion\n",
    "\n",
    "#### Challenge 4: External Factors\n",
    "**Problem:**\n",
    "- Seasonality, competitors, economy, COVID-19, etc.\n",
    "- Can confound marketing effects\n",
    "\n",
    "**Solutions:**\n",
    "- Include control variables (weather, holidays, etc.)\n",
    "- Use time series decomposition\n",
    "- Consider difference-in-differences for events\n",
    "- Synthetic control methods\n",
    "\n",
    "#### Challenge 5: Model Validation\n",
    "**Problem:**\n",
    "- How do we know the model is accurate?\n",
    "- Historical fit \u2260 predictive accuracy\n",
    "\n",
    "**Solutions:**\n",
    "- Hold-out test sets\n",
    "- Cross-validation\n",
    "- Incrementality tests (geo experiments)\n",
    "- Business logic sanity checks\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "#### For MMM:\n",
    "1. \u2705 **Data Requirements:**\n",
    "   - Minimum 2 years of weekly data\n",
    "   - Include all relevant channels\n",
    "   - Account for seasonality and trends\n",
    "\n",
    "2. \u2705 **Model Building:**\n",
    "   - Start simple, add complexity gradually\n",
    "   - Test different adstock decay rates\n",
    "   - Validate saturation curves make business sense\n",
    "   - Use regularization to prevent overfitting\n",
    "\n",
    "3. \u2705 **Interpretation:**\n",
    "   - Focus on relative contributions, not absolute\n",
    "   - Check if ROI estimates align with business knowledge\n",
    "   - Consider confidence intervals\n",
    "   - Update models regularly (quarterly)\n",
    "\n",
    "#### For MTA:\n",
    "1. \u2705 **Data Requirements:**\n",
    "   - Comprehensive tracking across channels\n",
    "   - User ID resolution (cross-device)\n",
    "   - Clean data pipeline\n",
    "\n",
    "2. \u2705 **Model Selection:**\n",
    "   - Start with simple models (last-touch)\n",
    "   - Compare multiple models\n",
    "   - Consider data-driven attribution if volume permits\n",
    "   - Segment by customer type/product\n",
    "\n",
    "3. \u2705 **Interpretation:**\n",
    "   - Validate against incrementality tests\n",
    "   - Consider journey patterns, not just attribution\n",
    "   - Account for view-through vs click-through\n",
    "   - Monitor model stability over time\n",
    "\n",
    "### Incrementality Testing: The Gold Standard\n",
    "\n",
    "Both MMM and MTA have limitations. **Incrementality testing** provides ground truth:\n",
    "\n",
    "- **Geo Experiments:** Turn off marketing in test markets\n",
    "- **Holdout Tests:** Exclude random users from campaigns\n",
    "- **A/B Tests:** Randomized experiments\n",
    "\n",
    "Use incrementality tests to:\n",
    "- Validate MMM/MTA models\n",
    "- Calibrate attribution models\n",
    "- Measure true causal impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: Model diagnostics and validation\n",
    "print(\"\ud83d\udd0d Model Diagnostics and Validation\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Check model assumptions\n",
    "from scipy import stats\n",
    "\n",
    "# Get residuals from MMM model\n",
    "train_residuals = train_data['sales'] - train_predictions\n",
    "\n",
    "# Create diagnostic plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Residuals over time\n",
    "axes[0, 0].scatter(train_data['date'], train_residuals, alpha=0.6, color='steelblue')\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Date', fontsize=10)\n",
    "axes[0, 0].set_ylabel('Residuals ($)', fontsize=10)\n",
    "axes[0, 0].set_title('Residuals Over Time', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# 2. Q-Q plot (normality test)\n",
    "stats.probplot(train_residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "axes[0, 1].set_title('Q-Q Plot (Normality Test)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals histogram\n",
    "axes[1, 0].hist(train_residuals, bins=30, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Residuals ($)', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=10)\n",
    "axes[1, 0].set_title('Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Predicted vs Actual\n",
    "axes[1, 1].scatter(train_predictions, train_data['sales'], alpha=0.6, color='darkgreen')\n",
    "# Perfect prediction line\n",
    "min_val = min(train_predictions.min(), train_data['sales'].min())\n",
    "max_val = max(train_predictions.max(), train_data['sales'].max())\n",
    "axes[1, 1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1, 1].set_xlabel('Predicted Sales ($)', fontsize=10)\n",
    "axes[1, 1].set_ylabel('Actual Sales ($)', fontsize=10)\n",
    "axes[1, 1].set_title('Predicted vs Actual Sales', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=10)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "axes[1, 1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests\n",
    "print(\"\\n\ud83d\udcca Statistical Diagnostics:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Normality test\n",
    "from scipy.stats import shapiro, anderson\n",
    "shapiro_stat, shapiro_p = shapiro(train_residuals)\n",
    "print(f\"Shapiro-Wilk Test (Normality): p-value = {shapiro_p:.4f}\")\n",
    "if shapiro_p > 0.05:\n",
    "    print(\"  \u2713 Residuals appear normally distributed\")\n",
    "else:\n",
    "    print(\"  \u26a0 Residuals may not be normally distributed\")\n",
    "\n",
    "# Autocorrelation test\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "dw_stat = durbin_watson(train_residuals)\n",
    "print(f\"\\nDurbin-Watson Test (Autocorrelation): {dw_stat:.4f}\")\n",
    "print(\"  (Values 1.5-2.5 suggest low autocorrelation)\")\n",
    "if 1.5 <= dw_stat <= 2.5:\n",
    "    print(\"  \u2713 Low autocorrelation detected\")\n",
    "else:\n",
    "    print(\"  \u26a0 Significant autocorrelation may be present\")\n",
    "\n",
    "# Mean absolute percentage error\n",
    "mape = np.mean(np.abs(train_residuals / train_data['sales'])) * 100\n",
    "print(f\"\\nMean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "print(\"\\n\u2705 Model diagnostics completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section6'></a>\n",
    "## 6. Hands-On Exercise: Budget Optimization\n",
    "\n",
    "### Scenario:\n",
    "You're a Marketing Analytics Manager at an e-commerce company. You have:\n",
    "- Annual marketing budget: $5 million\n",
    "- Goal: Maximize ROI while maintaining brand presence\n",
    "- Constraints: Minimum spend requirements for brand channels\n",
    "\n",
    "### Task:\n",
    "Use the MMM model to optimize budget allocation and create a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget optimization exercise\n",
    "print(\"\ud83d\udcb0 Budget Optimization Exercise\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Current allocation (from training data)\n",
    "current_annual_spend = {}\n",
    "for channel in marketing_channels:\n",
    "    current_annual_spend[channel] = train_data[channel].sum()\n",
    "\n",
    "total_current = sum(current_annual_spend.values())\n",
    "\n",
    "print(\"\ud83d\udcca Current Annual Spend:\")\n",
    "print(\"-\" * 70)\n",
    "for channel, spend in sorted(current_annual_spend.items(), key=lambda x: -x[1]):\n",
    "    pct = (spend / total_current) * 100\n",
    "    print(f\"{channel.replace('_spend', '').title():15} ${spend:>12,.0f}  ({pct:>5.1f}%)\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'TOTAL':15} ${total_current:>12,.0f}  (100.0%)\")\n",
    "\n",
    "# Get ROI analysis\n",
    "roi_data = mmm_model.get_roi(train_data, train_data['sales'])\n",
    "\n",
    "print(\"\\n\ud83d\udcc8 Current ROI by Channel:\")\n",
    "print(\"-\" * 70)\n",
    "for _, row in roi_data.iterrows():\n",
    "    print(f\"{row['channel'].replace('_spend', '').title():15} ROI: {row['roi']:>6.2f}x\")\n",
    "\n",
    "# Simple optimization: Allocate based on ROI with constraints\n",
    "print(\"\\n\ud83c\udfaf Optimized Budget Allocation:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Strategy: Increase spend on high-ROI channels, decrease on low-ROI channels\")\n",
    "print(\"Constraint: Maintain at least 60% of current spend for brand channels (TV)\\n\")\n",
    "\n",
    "# New budget: $5M\n",
    "new_total_budget = 5_000_000\n",
    "\n",
    "# Optimization logic\n",
    "optimized_spend = {}\n",
    "roi_dict = dict(zip(roi_data['channel'], roi_data['roi']))\n",
    "\n",
    "# TV maintains 60% of current (brand presence)\n",
    "tv_min = current_annual_spend['tv_spend'] * 0.6\n",
    "remaining_budget = new_total_budget - tv_min\n",
    "\n",
    "# Allocate remaining based on ROI\n",
    "other_channels = [c for c in marketing_channels if c != 'tv_spend']\n",
    "total_roi = sum([roi_dict[c] for c in other_channels])\n",
    "\n",
    "optimized_spend['tv_spend'] = tv_min\n",
    "for channel in other_channels:\n",
    "    channel_roi = roi_dict[channel]\n",
    "    allocation = remaining_budget * (channel_roi / total_roi)\n",
    "    optimized_spend[channel] = allocation\n",
    "\n",
    "print(\"\\nOPTIMIZED ALLOCATION:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Channel':<15} {'Current':>15} {'Optimized':>15} {'Change':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for channel in marketing_channels:\n",
    "    current = current_annual_spend[channel]\n",
    "    optimized = optimized_spend[channel]\n",
    "    change = ((optimized - current) / current) * 100\n",
    "    \n",
    "    channel_name = channel.replace('_spend', '').title()\n",
    "    print(f\"{channel_name:<15} ${current:>14,.0f} ${optimized:>14,.0f} {change:>13.1f}%\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'TOTAL':<15} ${sum(current_annual_spend.values()):>14,.0f} ${new_total_budget:>14,.0f}\")\n",
    "\n",
    "# Estimate impact\n",
    "print(\"\\n\ud83d\udca1 Expected Impact:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Rough estimate of sales lift\n",
    "current_incremental = sum([roi_dict[ch] * current_annual_spend[ch] for ch in marketing_channels])\n",
    "optimized_incremental = sum([roi_dict[ch] * optimized_spend[ch] for ch in marketing_channels])\n",
    "\n",
    "lift = ((optimized_incremental - current_incremental) / current_incremental) * 100\n",
    "\n",
    "print(f\"Estimated sales lift: +{lift:.1f}%\")\n",
    "print(f\"Additional revenue: ${optimized_incremental - current_incremental:,.0f}\")\n",
    "print(\"\\n\u26a0\ufe0f  Note: This is a simplified optimization. In practice, you should:\")\n",
    "print(\"   \u2022 Test changes incrementally\")\n",
    "print(\"   \u2022 Consider saturation effects at higher spend levels\")\n",
    "print(\"   \u2022 Account for competitive responses\")\n",
    "print(\"   \u2022 Monitor performance and adjust\")\n",
    "\n",
    "# Visualize the optimization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "channels_clean = [c.replace('_spend', '').title() for c in marketing_channels]\n",
    "current_values = [current_annual_spend[c] for c in marketing_channels]\n",
    "optimized_values = [optimized_spend[c] for c in marketing_channels]\n",
    "\n",
    "x = np.arange(len(channels_clean))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, current_values, width, label='Current', color='lightblue', alpha=0.8)\n",
    "axes[0].bar(x + width/2, optimized_values, width, label='Optimized', color='lightcoral', alpha=0.8)\n",
    "axes[0].set_ylabel('Annual Spend ($)', fontsize=11)\n",
    "axes[0].set_title('Budget Allocation Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(channels_clean, rotation=15, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))\n",
    "\n",
    "# Pie chart of optimized allocation\n",
    "colors_pie = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "axes[1].pie(optimized_values, labels=channels_clean, autopct='%1.1f%%', \n",
    "           startangle=90, colors=colors_pie)\n",
    "axes[1].set_title('Optimized Budget Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2705 Budget optimization exercise completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section7'></a>\n",
    "## 7. Summary and Best Practices\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "#### Marketing Mix Modeling (MMM)\n",
    "- \u2705 **Top-down approach** for understanding aggregate marketing effectiveness\n",
    "- \u2705 **Includes offline channels** (TV, Radio, Print) alongside digital\n",
    "- \u2705 **Captures carryover effects** through adstock transformation\n",
    "- \u2705 **Models diminishing returns** via saturation curves\n",
    "- \u2705 **Best for strategic planning** and long-term budget allocation\n",
    "- \u26a0\ufe0f Requires 2-3 years of data, updated quarterly/annually\n",
    "\n",
    "#### Multi-Touch Attribution (MTA)\n",
    "- \u2705 **Bottom-up approach** analyzing individual customer journeys\n",
    "- \u2705 **Granular insights** into digital touchpoint effectiveness\n",
    "- \u2705 **Real-time optimization** capabilities\n",
    "- \u2705 **Multiple models available**: Last-touch, Linear, Time-decay, Position-based\n",
    "- \u2705 **Best for digital optimization** and tactical decisions\n",
    "- \u26a0\ufe0f Limited offline coverage, privacy challenges\n",
    "\n",
    "#### When to Use Each\n",
    "- **MMM**: Offline presence, strategic planning, privacy-first environment\n",
    "- **MTA**: Digital-first business, real-time optimization, short sales cycles\n",
    "- **Both**: Omnichannel strategy, comprehensive analytics capabilities\n",
    "\n",
    "### Implementation Checklist\n",
    "\n",
    "#### Before You Start:\n",
    "- [ ] Define clear business objectives\n",
    "- [ ] Assess data availability and quality\n",
    "- [ ] Identify key marketing channels\n",
    "- [ ] Determine success metrics (ROI, ROAS, etc.)\n",
    "- [ ] Allocate resources (time, budget, team)\n",
    "\n",
    "#### For MMM Implementation:\n",
    "- [ ] Collect 2-3 years of weekly spend and sales data\n",
    "- [ ] Include all relevant channels (online + offline)\n",
    "- [ ] Gather external variables (seasonality, promotions, etc.)\n",
    "- [ ] Choose appropriate transformations (adstock, saturation)\n",
    "- [ ] Use regularization to prevent overfitting\n",
    "- [ ] Validate with hold-out data\n",
    "- [ ] Run incrementality tests to calibrate\n",
    "- [ ] Update model quarterly or annually\n",
    "\n",
    "#### For MTA Implementation:\n",
    "- [ ] Implement comprehensive tracking across channels\n",
    "- [ ] Resolve user identity (cross-device, cross-channel)\n",
    "- [ ] Define attribution window (7, 14, 30 days)\n",
    "- [ ] Choose attribution model(s) to use\n",
    "- [ ] Compare multiple models for robustness\n",
    "- [ ] Validate against incrementality tests\n",
    "- [ ] Monitor and update regularly\n",
    "- [ ] Ensure privacy compliance (GDPR, CCPA, etc.)\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "\n",
    "1. **Over-reliance on one approach** - Consider using both MMM and MTA\n",
    "2. **Ignoring data quality** - Garbage in, garbage out\n",
    "3. **Not validating models** - Use incrementality tests\n",
    "4. **Treating attribution as truth** - It's always an estimate\n",
    "5. **Forgetting context** - External factors matter\n",
    "6. **Static models** - Update regularly as market changes\n",
    "7. **Complexity for its own sake** - Start simple, add complexity as needed\n",
    "\n",
    "### The Future of Marketing Measurement\n",
    "\n",
    "#### Emerging Trends:\n",
    "- **Privacy-First Attribution** - Adapting to iOS 14+, cookie deprecation\n",
    "- **Unified Measurement** - Combining MMM and MTA insights\n",
    "- **Real-Time MMM** - More frequent model updates\n",
    "- **Machine Learning** - Automated model selection and optimization\n",
    "- **Incrementality-First** - More focus on causal inference\n",
    "- **Multi-Touch MMM** - Incorporating journey-level data into MMM\n",
    "\n",
    "### Resources for Further Learning\n",
    "\n",
    "#### Books:\n",
    "- *Marketing Analytics* by Winston & Goldsmith\n",
    "- *Digital Marketing Analytics* by Hemann & Burbary\n",
    "- *Causal Inference* by Pearl & Mackenzie\n",
    "\n",
    "#### Tools & Frameworks:\n",
    "- **Open Source:** PyMC-Marketing, Robyn (Meta), LightweightMMM (Google)\n",
    "- **Commercial:** Google Analytics, Adobe Analytics, Neustar, Nielsen\n",
    "\n",
    "#### Research:\n",
    "- Google's Meridian MMM framework\n",
    "- Meta's Robyn open-source MMM\n",
    "- Academic papers on causal inference in marketing\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations! \ud83c\udf89\n",
    "\n",
    "You've completed the Marketing Mix Modeling and Multi-Touch Attribution hands-on lab!\n",
    "\n",
    "You now understand:\n",
    "- \u2705 The challenges in marketing measurement\n",
    "- \u2705 How MMM provides top-down insights\n",
    "- \u2705 How MTA analyzes customer journeys\n",
    "- \u2705 When to use each approach\n",
    "- \u2705 Practical implementation considerations\n",
    "- \u2705 How to optimize marketing budgets\n",
    "\n",
    "### Next Steps:\n",
    "1. Apply these concepts to your own marketing data\n",
    "2. Experiment with different model configurations\n",
    "3. Validate findings with incrementality tests\n",
    "4. Combine insights from multiple approaches\n",
    "5. Share learnings with your organization\n",
    "\n",
    "**Happy Analyzing! \ud83d\udcca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83c\udf93 LAB COMPLETE: Marketing Mix Modeling & Multi-Touch Attribution\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nWhat we covered:\")\n",
    "print(\"  \u2705 Marketing measurement challenges\")\n",
    "print(\"  \u2705 MMM: Top-down media effectiveness analysis\")\n",
    "print(\"  \u2705 MTA: Bottom-up customer journey attribution\")\n",
    "print(\"  \u2705 Key differences and use cases\")\n",
    "print(\"  \u2705 Practical implementation considerations\")\n",
    "print(\"  \u2705 Budget optimization exercise\")\n",
    "print(\"\\nThank you for completing this hands-on lab!\")\n",
    "print(\"\\n\ud83d\udca1 Remember: Marketing measurement is both art and science.\")\n",
    "print(\"   Combine quantitative insights with business judgment.\")\n",
    "print(\"\\n\ud83d\ude80 Now go forth and optimize your marketing!\\n\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}